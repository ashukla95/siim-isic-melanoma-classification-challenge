{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, GlobalAveragePooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import vgg16\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=100\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], size=10 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "#image = tf.cast(image, tf.float32)/255.0\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    r_crop = np.random.uniform(low = 0.4, high = 1.0)\n",
    "    r_rsize = np.random.uniform(low = 0.8, high = 1.2)\n",
    "    image = tf.image.random_crop(image, (int(r_crop*IMG_HEIGHT), int(r_crop*IMG_WIDTH), 3))\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.keras.preprocessing.image.random_shear(image, 20)\n",
    "    image = tf.image.resize(image, (int(r_rsize*IMG_HEIGHT), int(r_rsize*IMG_WIDTH), 3), preserve_aspect_ratio=True)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_brightness(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train_df[[\"image_name\"]]\n",
    "# y_train = train_df[\"target\"].astype(np.float32).values\n",
    "# x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5139, 1), (1285, 1), (5139,), (1285,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55009634, 5.49038462])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_layer):\n",
    "    \n",
    "    pretrained_model = efn.EfficientNetB3(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "                                              weights='imagenet',\n",
    "                                              include_top=False\n",
    "                                             )\n",
    "    # False = transfer learning, True = fine-tuning\n",
    "    pretrained_model.trainable = True#False \n",
    "\n",
    "    inp1 = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='inp1')\n",
    "        \n",
    "\n",
    "    x=pretrained_model(inp1)\n",
    "    x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x=tf.keras.layers.Dense(2048, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "    x=tf.keras.layers.Dense(1024, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "    x=tf.keras.layers.Dense(512, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "    x=tf.keras.layers.Dense(256, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "    x=tf.keras.layers.Dense(128, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "    x=tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(l=REG),\n",
    "                                activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "        \n",
    "    model = tf.keras.models.Model(inputs=[inp1], outputs=[output])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss = dice_loss,\n",
    "        metrics=[tf.keras.metrics.AUC()],\n",
    "        )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp1 (InputLayer)            [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b3 (Model)      (None, 10, 10, 1536)      10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              3147776   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,726,825\n",
      "Trainable params: 16,639,529\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = create_model(input_layer=input_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 642 steps, validate for 160 steps\n",
      "Epoch 1/100\n",
      "642/642 [==============================] - 738s 1s/step - loss: 1.0809 - tp: 0.0000e+00 - fp: 2.0000 - tn: 4668.0000 - fn: 466.0000 - accuracy: 0.9089 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5153 - binary_crossentropy: 0.9735 - val_loss: 0.3249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1169.0000 - val_fn: 111.0000 - val_accuracy: 0.9133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5468 - val_binary_crossentropy: 0.7003\n",
      "Epoch 2/100\n",
      "642/642 [==============================] - 674s 1s/step - loss: 0.1687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4666.0000 - fn: 470.0000 - accuracy: 0.9085 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5054 - binary_crossentropy: 1.0264 - val_loss: 0.0937 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1165.0000 - val_fn: 115.0000 - val_accuracy: 0.9102 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5115 - val_binary_crossentropy: 0.8288\n",
      "Epoch 3/100\n",
      "642/642 [==============================] - 674s 1s/step - loss: 0.0743 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4671.0000 - fn: 465.0000 - accuracy: 0.9095 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5074 - binary_crossentropy: 1.0517 - val_loss: 0.0602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1169.0000 - val_fn: 111.0000 - val_accuracy: 0.9133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5019 - val_binary_crossentropy: 0.8420\n",
      "Epoch 4/100\n",
      "642/642 [==============================] - 680s 1s/step - loss: 0.0574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4667.0000 - fn: 469.0000 - accuracy: 0.9087 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5045 - binary_crossentropy: 0.9872 - val_loss: 0.0537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1163.0000 - val_fn: 117.0000 - val_accuracy: 0.9086 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5085 - val_binary_crossentropy: 0.8753\n",
      "Epoch 5/100\n",
      "642/642 [==============================] - 684s 1s/step - loss: 0.0521 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4664.0000 - fn: 472.0000 - accuracy: 0.9081 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5028 - binary_crossentropy: 0.9677 - val_loss: 0.0491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1166.0000 - val_fn: 114.0000 - val_accuracy: 0.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 0.7946\n",
      "Epoch 6/100\n",
      "642/642 [==============================] - 694s 1s/step - loss: 0.0491 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4672.0000 - fn: 464.0000 - accuracy: 0.9097 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5033 - binary_crossentropy: 0.9006 - val_loss: 0.0498 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1161.0000 - val_fn: 119.0000 - val_accuracy: 0.9070 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4996 - val_binary_crossentropy: 0.7605\n",
      "Epoch 7/100\n",
      "642/642 [==============================] - 716s 1s/step - loss: 0.0484 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4669.0000 - fn: 467.0000 - accuracy: 0.9091 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5044 - binary_crossentropy: 0.8858 - val_loss: 0.0458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1170.0000 - val_fn: 110.0000 - val_accuracy: 0.9141 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4983 - val_binary_crossentropy: 0.7952\n",
      "Epoch 8/100\n",
      "642/642 [==============================] - 650s 1s/step - loss: 0.0489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4659.0000 - fn: 477.0000 - accuracy: 0.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5106 - binary_crossentropy: 0.9081 - val_loss: 0.0492 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1160.0000 - val_fn: 120.0000 - val_accuracy: 0.9062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5154 - val_binary_crossentropy: 0.8632\n",
      "Epoch 9/100\n",
      "642/642 [==============================] - 646s 1s/step - loss: 0.0475 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4671.0000 - fn: 465.0000 - accuracy: 0.9095 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5171 - binary_crossentropy: 0.8782 - val_loss: 0.0462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1167.0000 - val_fn: 113.0000 - val_accuracy: 0.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5088 - val_binary_crossentropy: 0.7963\n",
      "Epoch 10/100\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.0478 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4659.0000 - fn: 469.0000 - accuracy: 0.9085 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5121 - binary_crossentropy: 0.8757\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "642/642 [==============================] - 643s 1s/step - loss: 0.0478 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4666.0000 - fn: 470.0000 - accuracy: 0.9085 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5120 - binary_crossentropy: 0.8761 - val_loss: 0.0476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1163.0000 - val_fn: 117.0000 - val_accuracy: 0.9086 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5282 - val_binary_crossentropy: 0.8506\n",
      "Epoch 11/100\n",
      "642/642 [==============================] - 649s 1s/step - loss: 0.0469 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4674.0000 - fn: 462.0000 - accuracy: 0.9100 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5225 - binary_crossentropy: 0.8428 - val_loss: 0.0483 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1161.0000 - val_fn: 119.0000 - val_accuracy: 0.9070 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5352 - val_binary_crossentropy: 0.8340\n",
      "Epoch 12/100\n",
      "642/642 [==============================] - 647s 1s/step - loss: 0.0478 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4664.0000 - fn: 472.0000 - accuracy: 0.9081 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5267 - binary_crossentropy: 0.8306 - val_loss: 0.0486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1160.0000 - val_fn: 120.0000 - val_accuracy: 0.9062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5444 - val_binary_crossentropy: 0.8021\n",
      "Epoch 13/100\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.0461 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4673.0000 - fn: 455.0000 - accuracy: 0.9113 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5337 - binary_crossentropy: 0.7932\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "642/642 [==============================] - 652s 1s/step - loss: 0.0460 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4681.0000 - fn: 455.0000 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5337 - binary_crossentropy: 0.7920 - val_loss: 0.0463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1166.0000 - val_fn: 114.0000 - val_accuracy: 0.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5563 - val_binary_crossentropy: 0.7447\n",
      "Epoch 14/100\n",
      "642/642 [==============================] - 652s 1s/step - loss: 0.0481 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4659.0000 - fn: 477.0000 - accuracy: 0.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5525 - binary_crossentropy: 0.8013 - val_loss: 0.0481 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1161.0000 - val_fn: 119.0000 - val_accuracy: 0.9070 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5438 - val_binary_crossentropy: 0.7243\n",
      "Epoch 15/100\n",
      "642/642 [==============================] - 652s 1s/step - loss: 0.0465 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4675.0000 - fn: 461.0000 - accuracy: 0.9102 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5561 - binary_crossentropy: 0.7574 - val_loss: 0.0443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1171.0000 - val_fn: 109.0000 - val_accuracy: 0.9148 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5491 - val_binary_crossentropy: 0.7405\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/642 [============================>.] - ETA: 0s - loss: 0.0479 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4652.0000 - fn: 476.0000 - accuracy: 0.9072 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6041 - binary_crossentropy: 0.7382\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "642/642 [==============================] - 654s 1s/step - loss: 0.0479 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4659.0000 - fn: 477.0000 - accuracy: 0.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6049 - binary_crossentropy: 0.7376 - val_loss: 0.0490 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1159.0000 - val_fn: 121.0000 - val_accuracy: 0.9055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6178 - val_binary_crossentropy: 0.7244\n",
      "Epoch 17/100\n",
      "642/642 [==============================] - 644s 1s/step - loss: 0.0468 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4670.0000 - fn: 466.0000 - accuracy: 0.9093 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6378 - binary_crossentropy: 0.6527 - val_loss: 0.0466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1166.0000 - val_fn: 114.0000 - val_accuracy: 0.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6429 - val_binary_crossentropy: 0.6028\n",
      "Epoch 18/100\n",
      "642/642 [==============================] - 644s 1s/step - loss: 0.0472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4660.0000 - fn: 476.0000 - accuracy: 0.9073 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6744 - binary_crossentropy: 0.6227 - val_loss: 0.0474 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1164.0000 - val_fn: 116.0000 - val_accuracy: 0.9094 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6604 - val_binary_crossentropy: 0.6090\n",
      "Epoch 19/100\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.0441 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4675.0000 - fn: 453.0000 - accuracy: 0.9117 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6948 - binary_crossentropy: 0.5670\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "642/642 [==============================] - 638s 994ms/step - loss: 0.0442 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4682.0000 - fn: 454.0000 - accuracy: 0.9116 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6944 - binary_crossentropy: 0.5680 - val_loss: 0.0462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1167.0000 - val_fn: 113.0000 - val_accuracy: 0.9117 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6590 - val_binary_crossentropy: 0.6242\n",
      "Epoch 20/100\n",
      "642/642 [==============================] - 645s 1s/step - loss: 0.0433 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4662.0000 - fn: 474.0000 - accuracy: 0.9077 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7114 - binary_crossentropy: 0.5612 - val_loss: 0.0476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1169.0000 - val_fn: 111.0000 - val_accuracy: 0.9133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6476 - val_binary_crossentropy: 0.6143\n",
      "Epoch 21/100\n",
      "642/642 [==============================] - 645s 1s/step - loss: 0.0408 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4673.0000 - fn: 463.0000 - accuracy: 0.9099 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7176 - binary_crossentropy: 0.5470 - val_loss: 0.0500 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1160.0000 - val_fn: 120.0000 - val_accuracy: 0.9062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_binary_crossentropy: 0.6365\n",
      "Epoch 22/100\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.0404 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4670.0000 - fn: 458.0000 - accuracy: 0.9107 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7153 - binary_crossentropy: 0.5441\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "642/642 [==============================] - 643s 1s/step - loss: 0.0405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4676.0000 - fn: 460.0000 - accuracy: 0.9104 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7154 - binary_crossentropy: 0.5464 - val_loss: 0.0480 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1164.0000 - val_fn: 116.0000 - val_accuracy: 0.9094 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6590 - val_binary_crossentropy: 0.6102\n",
      "Epoch 23/100\n",
      "642/642 [==============================] - 645s 1s/step - loss: 0.0411 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4658.0000 - fn: 478.0000 - accuracy: 0.9069 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7264 - binary_crossentropy: 0.5503 - val_loss: 0.0449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1173.0000 - val_fn: 107.0000 - val_accuracy: 0.9164 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6507 - val_binary_crossentropy: 0.5615\n",
      "Epoch 24/100\n",
      "642/642 [==============================] - 648s 1s/step - loss: 0.0394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4672.0000 - fn: 464.0000 - accuracy: 0.9097 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7260 - binary_crossentropy: 0.5270 - val_loss: 0.0461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1168.0000 - val_fn: 112.0000 - val_accuracy: 0.9125 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6802 - val_binary_crossentropy: 0.5672\n",
      "Epoch 25/100\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.0394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4663.0000 - fn: 465.0000 - accuracy: 0.9093 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7296 - binary_crossentropy: 0.5282\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "642/642 [==============================] - 639s 995ms/step - loss: 0.0393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4671.0000 - fn: 465.0000 - accuracy: 0.9095 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7297 - binary_crossentropy: 0.5273 - val_loss: 0.0475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1164.0000 - val_fn: 116.0000 - val_accuracy: 0.9094 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6809 - val_binary_crossentropy: 0.5974\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa84b42b88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3005409e-06],\n",
       "       [3.5176547e-06],\n",
       "       [2.7030246e-06],\n",
       "       ...,\n",
       "       [4.9238235e-01],\n",
       "       [6.8428158e-06],\n",
       "       [8.6698653e-03]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>0.492382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.008670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "0      ISIC_0052060  0.000006\n",
       "1      ISIC_0052349  0.000004\n",
       "2      ISIC_0058510  0.000003\n",
       "3      ISIC_0073313  0.000007\n",
       "4      ISIC_0073502  0.000019\n",
       "...             ...       ...\n",
       "10977  ISIC_9992485  0.000013\n",
       "10978  ISIC_9996992  0.000034\n",
       "10979  ISIC_9997917  0.492382\n",
       "10980  ISIC_9998234  0.000007\n",
       "10981  ISIC_9999302  0.008670\n",
       "\n",
       "[10982 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"efnb3_barzil_researcher_image_augmentation_exp_4x_imbalance_data_2048_cells_100_epochs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
