{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=1 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.adjust_brightness(image, 0.2)\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.3)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelEncoder()\n",
    "# image_names = train_df[\"image_name\"].values\n",
    "# train_df[\"image_name\"] = lb.fit_transform(train_df[\"image_name\"].values)\n",
    "# train_df[\"target\"] = train_df[\"target\"].astype(\"int\")\n",
    "# train_df.head()\n",
    "# map_name_no = dict(zip(train_df[\"image_name\"], image_names))\n",
    "# y_train = train_df[\"target\"]\n",
    "# x_train = train_df[[\"image_name\"]]\n",
    "\n",
    "\n",
    "# over = SMOTE(random_state=45, sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# ppl = Pipeline(steps=steps)\n",
    "# x_train, y_train = ppl.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)\n",
    "# x_train[\"image_name\"] = x_train[\"image_name\"].apply(lambda x: map_name_no[x])\n",
    "# x_val[\"image_name\"] = x_val[\"image_name\"].apply(lambda x: map_name_no[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((934, 1), (234, 1), (934,), (234,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96887967, 1.03318584])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: Tensor(\"conv2d_7/Identity:0\", shape=(None, 37, 37, 64), dtype=float32) (None, 37, 37, 64), refer: Tensor(\"up_sampling2d/Identity:0\", shape=(None, 36, 36, 80), dtype=float32) (None, 36, 36, 80)\n",
      "target: Tensor(\"conv2d_5/Identity:0\", shape=(None, 75, 75, 48), dtype=float32) (None, 75, 75, 48), refer: Tensor(\"up_sampling2d_1/Identity:0\", shape=(None, 72, 72, 256), dtype=float32) (None, 72, 72, 256)\n",
      "target: Tensor(\"conv2d_3/Identity:0\", shape=(None, 150, 150, 32), dtype=float32) (None, 150, 150, 32), refer: Tensor(\"up_sampling2d_2/Identity:0\", shape=(None, 144, 144, 192), dtype=float32) (None, 144, 144, 192)\n",
      "target: Tensor(\"conv2d_1/Identity:0\", shape=(None, 300, 300, 16), dtype=float32) (None, 300, 300, 16), refer: Tensor(\"up_sampling2d_3/Identity:0\", shape=(None, 288, 288, 192), dtype=float32) (None, 288, 288, 192)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 300, 300, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 300, 300, 16) 2320        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 150, 150, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150, 150, 16) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 32) 4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 32) 9248        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 75, 75, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 48)   13872       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 48)   20784       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 37, 37, 48)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 37, 37, 64)   27712       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 37, 37, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 18, 18, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 18, 18, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 18, 18, 80)   46160       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 18, 18, 80)   57680       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 36, 36, 80)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 36, 36, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 36, 36, 144)  0           up_sampling2d[0][0]              \n",
      "                                                                 cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 36, 36, 144)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 36, 36, 256)  332032      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 36, 36, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 72, 72, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 72, 72, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 304)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 72, 72, 304)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 192)  525504      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 192)  331968      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 144, 144, 192 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 144, 144, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144, 144, 224 0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 144, 144, 224 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 144, 144, 192 387264      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 144, 144, 192 331968      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 288, 288, 192 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 288, 288, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 288, 288, 208 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 288, 288, 208 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 288, 288, 64) 119872      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 288, 288, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 288, 288, 1)  65          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 82944)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          21233920    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 24,210,770\n",
      "Trainable params: 24,209,490\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_unet(input_layer, expansion_filters=64, expansion_kernel=(3,3), expansion_pool_size=(2,2),\n",
    "          contract_filters=64, contract_kernel=(3,3), contract_pool_size=(2,2)):\n",
    "    \n",
    "    #64\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_1)\n",
    "    mp_lvl_1 = MaxPooling2D(expansion_pool_size)(lvl_1)\n",
    "    mp_lvl_1 = Dropout(0.25)(mp_lvl_1)\n",
    "    \n",
    "    #128\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_1)\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_2)\n",
    "    mp_lvl_2 = MaxPooling2D(expansion_pool_size)(lvl_2)\n",
    "    mp_lvl_2 = Dropout(0.25)(mp_lvl_2)\n",
    "    \n",
    "    #256\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_2)\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_3)\n",
    "    mp_lvl_3 = MaxPooling2D(expansion_pool_size)(lvl_3)\n",
    "    mp_lvl_3 = Dropout(0.25)(mp_lvl_3)\n",
    "    \n",
    "    #512\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_3)\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_4)\n",
    "    mp_lvl_4 = MaxPooling2D(expansion_pool_size)(lvl_4)\n",
    "    mp_lvl_4 = Dropout(0.25)(mp_lvl_4)\n",
    "    \n",
    "    #1024\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_4)\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    \n",
    "    #d_lvl_4 = Conv2DTranspose(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    d_lvl_4 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(lvl_5)\n",
    "    ch, cw = get_crop_shape(lvl_4, d_lvl_4)\n",
    "    ccon_4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_4)\n",
    "    ucon_4 = concatenate([d_lvl_4, ccon_4])\n",
    "    ucon_4 = Dropout(0.25)(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    \n",
    "    #d_lvl_3 = Conv2DTranspose(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    d_lvl_3 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_4)\n",
    "    ch, cw = get_crop_shape(lvl_3, d_lvl_3)\n",
    "    ccon_3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_3)\n",
    "    ucon_3 = concatenate([d_lvl_3, ccon_3])\n",
    "    ucon_3 = Dropout(0.25)(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    \n",
    "    #d_lvl_2 = Conv2DTranspose(filters=contract_filters*2, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    d_lvl_2 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_3)\n",
    "    ch, cw = get_crop_shape(lvl_2, d_lvl_2)\n",
    "    ccon_2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_2)\n",
    "    ucon_2 = concatenate([d_lvl_2, ccon_2])\n",
    "    ucon_2 = Dropout(0.25)(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    \n",
    "    #d_lvl_1 = Conv2DTranspose(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    d_lvl_1 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_2)\n",
    "    ch, cw = get_crop_shape(lvl_1, d_lvl_1)\n",
    "    ccon_1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_1)\n",
    "    ucon_1 = concatenate([d_lvl_1, ccon_1])\n",
    "    ucon_1 = Dropout(0.25)(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    output = Conv2D(filters=1, kernel_size=(1,1), activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    flatten = Flatten()(output)\n",
    "    dense4 = Dense(256, activation='relu')(flatten)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    dense3 = Dense(256, activation='relu')(bn4)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense2 = Dense(128, activation='relu')(bn3)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense1 = Dense(1, activation=\"sigmoid\")(bn2)\n",
    "    model = Model(inputs=input_layer, outputs=dense1)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = model_unet(input_layer, expansion_filters=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x1f87a5fba48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 116 steps, validate for 29 steps\n",
      "Epoch 1/40\n",
      "116/116 [==============================] - 147s 1s/step - loss: 0.2366 - tp: 279.0000 - fp: 225.0000 - tn: 255.0000 - fn: 169.0000 - accuracy: 0.5754 - precision: 0.5536 - recall: 0.6228 - auc: 0.5823 - binary_crossentropy: 1.0628 - val_loss: 0.2553 - val_tp: 45.0000 - val_fp: 18.0000 - val_tn: 79.0000 - val_fn: 90.0000 - val_accuracy: 0.5345 - val_precision: 0.7143 - val_recall: 0.3333 - val_auc: 0.6629 - val_binary_crossentropy: 0.6909\n",
      "Epoch 2/40\n",
      "116/116 [==============================] - 105s 909ms/step - loss: 0.2123 - tp: 283.0000 - fp: 207.0000 - tn: 259.0000 - fn: 179.0000 - accuracy: 0.5841 - precision: 0.5776 - recall: 0.6126 - auc: 0.6048 - binary_crossentropy: 2.0798 - val_loss: 0.2534 - val_tp: 112.0000 - val_fp: 54.0000 - val_tn: 47.0000 - val_fn: 19.0000 - val_accuracy: 0.6853 - val_precision: 0.6747 - val_recall: 0.8550 - val_auc: 0.6927 - val_binary_crossentropy: 0.6753\n",
      "Epoch 3/40\n",
      "116/116 [==============================] - 112s 968ms/step - loss: 0.1909 - tp: 300.0000 - fp: 205.0000 - tn: 287.0000 - fn: 136.0000 - accuracy: 0.6325 - precision: 0.5941 - recall: 0.6881 - auc: 0.6576 - binary_crossentropy: 1.9330 - val_loss: 0.2532 - val_tp: 10.0000 - val_fp: 6.0000 - val_tn: 99.0000 - val_fn: 117.0000 - val_accuracy: 0.4698 - val_precision: 0.6250 - val_recall: 0.0787 - val_auc: 0.6901 - val_binary_crossentropy: 0.8702\n",
      "Epoch 4/40\n",
      "116/116 [==============================] - 114s 987ms/step - loss: 0.1776 - tp: 315.0000 - fp: 201.0000 - tn: 293.0000 - fn: 119.0000 - accuracy: 0.6552 - precision: 0.6105 - recall: 0.7258 - auc: 0.6842 - binary_crossentropy: 1.9874 - val_loss: 0.2353 - val_tp: 120.0000 - val_fp: 98.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.5603 - val_precision: 0.5505 - val_recall: 0.9677 - val_auc: 0.6169 - val_binary_crossentropy: 0.8785\n",
      "Epoch 5/40\n",
      "116/116 [==============================] - 117s 1s/step - loss: 0.1722 - tp: 295.0000 - fp: 154.0000 - tn: 318.0000 - fn: 161.0000 - accuracy: 0.6606 - precision: 0.6570 - recall: 0.6469 - auc: 0.6922 - binary_crossentropy: 2.0939 - val_loss: 0.2308 - val_tp: 33.0000 - val_fp: 13.0000 - val_tn: 89.0000 - val_fn: 97.0000 - val_accuracy: 0.5259 - val_precision: 0.7174 - val_recall: 0.2538 - val_auc: 0.6694 - val_binary_crossentropy: 1.9866\n",
      "Epoch 6/40\n",
      "116/116 [==============================] - 118s 1s/step - loss: 0.1705 - tp: 306.0000 - fp: 168.0000 - tn: 313.0000 - fn: 141.0000 - accuracy: 0.6670 - precision: 0.6456 - recall: 0.6846 - auc: 0.6906 - binary_crossentropy: 2.2528 - val_loss: 0.2022 - val_tp: 50.0000 - val_fp: 8.0000 - val_tn: 87.0000 - val_fn: 87.0000 - val_accuracy: 0.5905 - val_precision: 0.8621 - val_recall: 0.3650 - val_auc: 0.6651 - val_binary_crossentropy: 3.9403\n",
      "Epoch 7/40\n",
      "116/116 [==============================] - 119s 1s/step - loss: 0.1691 - tp: 323.0000 - fp: 180.0000 - tn: 302.0000 - fn: 123.0000 - accuracy: 0.6735 - precision: 0.6421 - recall: 0.7242 - auc: 0.6900 - binary_crossentropy: 2.1197 - val_loss: 0.1900 - val_tp: 64.0000 - val_fp: 27.0000 - val_tn: 80.0000 - val_fn: 61.0000 - val_accuracy: 0.6207 - val_precision: 0.7033 - val_recall: 0.5120 - val_auc: 0.6765 - val_binary_crossentropy: 3.0398\n",
      "Epoch 8/40\n",
      "116/116 [==============================] - 121s 1s/step - loss: 0.1839 - tp: 301.0000 - fp: 179.0000 - tn: 289.0000 - fn: 159.0000 - accuracy: 0.6358 - precision: 0.6271 - recall: 0.6543 - auc: 0.6605 - binary_crossentropy: 2.6089 - val_loss: 0.2221 - val_tp: 127.0000 - val_fp: 104.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5517 - val_precision: 0.5498 - val_recall: 1.0000 - val_auc: 0.5988 - val_binary_crossentropy: 3.4500\n",
      "Epoch 9/40\n",
      "116/116 [==============================] - 120s 1s/step - loss: 0.1672 - tp: 332.0000 - fp: 186.0000 - tn: 291.0000 - fn: 119.0000 - accuracy: 0.6713 - precision: 0.6409 - recall: 0.7361 - auc: 0.6914 - binary_crossentropy: 2.3984 - val_loss: 0.2011 - val_tp: 132.0000 - val_fp: 87.0000 - val_tn: 11.0000 - val_fn: 2.0000 - val_accuracy: 0.6164 - val_precision: 0.6027 - val_recall: 0.9851 - val_auc: 0.5745 - val_binary_crossentropy: 3.0136\n",
      "Epoch 10/40\n",
      "116/116 [==============================] - 121s 1s/step - loss: 0.1627 - tp: 309.0000 - fp: 172.0000 - tn: 317.0000 - fn: 130.0000 - accuracy: 0.6746 - precision: 0.6424 - recall: 0.7039 - auc: 0.7042 - binary_crossentropy: 2.3584 - val_loss: 0.1436 - val_tp: 95.0000 - val_fp: 31.0000 - val_tn: 69.0000 - val_fn: 37.0000 - val_accuracy: 0.7069 - val_precision: 0.7540 - val_recall: 0.7197 - val_auc: 0.7688 - val_binary_crossentropy: 1.4933\n",
      "Epoch 11/40\n",
      "116/116 [==============================] - 121s 1s/step - loss: 0.1880 - tp: 293.0000 - fp: 176.0000 - tn: 293.0000 - fn: 166.0000 - accuracy: 0.6315 - precision: 0.6247 - recall: 0.6383 - auc: 0.6508 - binary_crossentropy: 2.3735 - val_loss: 0.2850 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 95.0000 - val_fn: 132.0000 - val_accuracy: 0.4310 - val_precision: 1.0000 - val_recall: 0.0365 - val_auc: 0.5182 - val_binary_crossentropy: 14.0636\n",
      "Epoch 12/40\n",
      "116/116 [==============================] - 121s 1s/step - loss: 0.1731 - tp: 306.0000 - fp: 185.0000 - tn: 309.0000 - fn: 128.0000 - accuracy: 0.6627 - precision: 0.6232 - recall: 0.7051 - auc: 0.6960 - binary_crossentropy: 2.1650 - val_loss: 0.1918 - val_tp: 143.0000 - val_fp: 89.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.6164 - val_precision: 0.6164 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 7.5196\n",
      "Epoch 13/40\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.1630 - tp: 323.0000 - fp: 154.0000 - tn: 305.0000 - fn: 138.0000 - accuracy: 0.6826 - precision: 0.6771 - recall: 0.7007 - auc: 0.6933 - binary_crossentropy: 2.3563\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "116/116 [==============================] - 122s 1s/step - loss: 0.1634 - tp: 324.0000 - fp: 156.0000 - tn: 309.0000 - fn: 139.0000 - accuracy: 0.6821 - precision: 0.6750 - recall: 0.6998 - auc: 0.6926 - binary_crossentropy: 2.3588 - val_loss: 0.2392 - val_tp: 121.0000 - val_fp: 111.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5216 - val_precision: 0.5216 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 6.0025\n",
      "Epoch 14/40\n",
      "116/116 [==============================] - 122s 1s/step - loss: 0.1690 - tp: 326.0000 - fp: 176.0000 - tn: 294.0000 - fn: 132.0000 - accuracy: 0.6681 - precision: 0.6494 - recall: 0.7118 - auc: 0.6809 - binary_crossentropy: 2.5574 - val_loss: 0.2155 - val_tp: 132.0000 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5690 - val_precision: 0.5690 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 4.4467\n",
      "Epoch 15/40\n",
      "116/116 [==============================] - 122s 1s/step - loss: 0.1703 - tp: 312.0000 - fp: 201.0000 - tn: 305.0000 - fn: 110.0000 - accuracy: 0.6649 - precision: 0.6082 - recall: 0.7393 - auc: 0.6923 - binary_crossentropy: 2.5844 - val_loss: 0.2091 - val_tp: 135.0000 - val_fp: 97.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5819 - val_precision: 0.5819 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 4.9599\n",
      "Epoch 16/40\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.1616 - tp: 346.0000 - fp: 172.0000 - tn: 283.0000 - fn: 119.0000 - accuracy: 0.6837 - precision: 0.6680 - recall: 0.7441 - auc: 0.6980 - binary_crossentropy: 2.3920\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "116/116 [==============================] - 123s 1s/step - loss: 0.1618 - tp: 349.0000 - fp: 174.0000 - tn: 285.0000 - fn: 120.0000 - accuracy: 0.6832 - precision: 0.6673 - recall: 0.7441 - auc: 0.6975 - binary_crossentropy: 2.4014 - val_loss: 0.2155 - val_tp: 132.0000 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5690 - val_precision: 0.5690 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 4.8334\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 122s 1s/step - loss: 0.1640 - tp: 338.0000 - fp: 195.0000 - tn: 291.0000 - fn: 104.0000 - accuracy: 0.6778 - precision: 0.6341 - recall: 0.7647 - auc: 0.6947 - binary_crossentropy: 2.5015 - val_loss: 0.2155 - val_tp: 132.0000 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5690 - val_precision: 0.5690 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 3.6353\n",
      "Epoch 18/40\n",
      "116/116 [==============================] - 123s 1s/step - loss: 0.1689 - tp: 350.0000 - fp: 209.0000 - tn: 266.0000 - fn: 103.0000 - accuracy: 0.6638 - precision: 0.6261 - recall: 0.7726 - auc: 0.6796 - binary_crossentropy: 2.4850 - val_loss: 0.2435 - val_tp: 119.0000 - val_fp: 113.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5129 - val_precision: 0.5129 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 4.1243\n",
      "Epoch 19/40\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.1575 - tp: 339.0000 - fp: 185.0000 - tn: 292.0000 - fn: 104.0000 - accuracy: 0.6859 - precision: 0.6469 - recall: 0.7652 - auc: 0.7013 - binary_crossentropy: 2.3094\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "116/116 [==============================] - 123s 1s/step - loss: 0.1573 - tp: 344.0000 - fp: 186.0000 - tn: 293.0000 - fn: 105.0000 - accuracy: 0.6864 - precision: 0.6491 - recall: 0.7661 - auc: 0.6999 - binary_crossentropy: 2.3140 - val_loss: 0.2177 - val_tp: 131.0000 - val_fp: 101.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5647 - val_precision: 0.5647 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 3.3968\n",
      "Epoch 20/40\n",
      "116/116 [==============================] - 124s 1s/step - loss: 0.1678 - tp: 338.0000 - fp: 198.0000 - tn: 282.0000 - fn: 110.0000 - accuracy: 0.6681 - precision: 0.6306 - recall: 0.7545 - auc: 0.6912 - binary_crossentropy: 2.5239 - val_loss: 0.2328 - val_tp: 124.0000 - val_fp: 108.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5345 - val_precision: 0.5345 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 3.7112\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f87b814508>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99926645],\n",
       "       [0.9994809 ],\n",
       "       [0.9988951 ],\n",
       "       ...,\n",
       "       [0.9998274 ],\n",
       "       [0.999406  ],\n",
       "       [0.999828  ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.999266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.998895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.999834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.999822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>0.999827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.999828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "0      ISIC_0052060  0.999266\n",
       "1      ISIC_0052349  0.999481\n",
       "2      ISIC_0058510  0.998895\n",
       "3      ISIC_0073313  0.999193\n",
       "4      ISIC_0073502  0.999834\n",
       "...             ...       ...\n",
       "10977  ISIC_9992485  0.999819\n",
       "10978  ISIC_9996992  0.999822\n",
       "10979  ISIC_9997917  0.999827\n",
       "10980  ISIC_9998234  0.999406\n",
       "10981  ISIC_9999302  0.999828\n",
       "\n",
       "[10982 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"dice_loss_unet_2d_images_hsv_augment_equal_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f87b814508>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_data': None,\n",
       " 'model': <tensorflow.python.keras.engine.training.Model at 0x1f87a5fba48>,\n",
       " '_chief_worker_only': None,\n",
       " 'params': {'batch_size': None,\n",
       "  'epochs': 40,\n",
       "  'steps': 116,\n",
       "  'samples': 116,\n",
       "  'verbose': 0,\n",
       "  'do_validation': True,\n",
       "  'metrics': ['loss',\n",
       "   'tp',\n",
       "   'fp',\n",
       "   'tn',\n",
       "   'fn',\n",
       "   'accuracy',\n",
       "   'precision',\n",
       "   'recall',\n",
       "   'auc',\n",
       "   'binary_crossentropy',\n",
       "   'val_loss',\n",
       "   'val_tp',\n",
       "   'val_fp',\n",
       "   'val_tn',\n",
       "   'val_fn',\n",
       "   'val_accuracy',\n",
       "   'val_precision',\n",
       "   'val_recall',\n",
       "   'val_auc',\n",
       "   'val_binary_crossentropy']},\n",
       " 'epoch': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19],\n",
       " 'history': {'loss': [0.23659261470210963,\n",
       "   0.2122536227107048,\n",
       "   0.1909219577009308,\n",
       "   0.17756300387454443,\n",
       "   0.17215824660299153,\n",
       "   0.17054572084854389,\n",
       "   0.16909694080722742,\n",
       "   0.18390476748604198,\n",
       "   0.16724883720021824,\n",
       "   0.1626689574713337,\n",
       "   0.18799499589307556,\n",
       "   0.17313331995030928,\n",
       "   0.16335389718156437,\n",
       "   0.16899753008680096,\n",
       "   0.17030654719163632,\n",
       "   0.16183635785148062,\n",
       "   0.16399539660277038,\n",
       "   0.16888612290394717,\n",
       "   0.15729268351248626,\n",
       "   0.16781897354742575],\n",
       "  'tp': [279.0,\n",
       "   283.0,\n",
       "   300.0,\n",
       "   315.0,\n",
       "   295.0,\n",
       "   306.0,\n",
       "   323.0,\n",
       "   301.0,\n",
       "   332.0,\n",
       "   309.0,\n",
       "   293.0,\n",
       "   306.0,\n",
       "   324.0,\n",
       "   326.0,\n",
       "   312.0,\n",
       "   349.0,\n",
       "   338.0,\n",
       "   350.0,\n",
       "   344.0,\n",
       "   338.0],\n",
       "  'fp': [225.0,\n",
       "   207.0,\n",
       "   205.0,\n",
       "   201.0,\n",
       "   154.0,\n",
       "   168.0,\n",
       "   180.0,\n",
       "   179.0,\n",
       "   186.0,\n",
       "   172.0,\n",
       "   176.0,\n",
       "   185.0,\n",
       "   156.0,\n",
       "   176.0,\n",
       "   201.0,\n",
       "   174.0,\n",
       "   195.0,\n",
       "   209.0,\n",
       "   186.0,\n",
       "   198.0],\n",
       "  'tn': [255.0,\n",
       "   259.0,\n",
       "   287.0,\n",
       "   293.0,\n",
       "   318.0,\n",
       "   313.0,\n",
       "   302.0,\n",
       "   289.0,\n",
       "   291.0,\n",
       "   317.0,\n",
       "   293.0,\n",
       "   309.0,\n",
       "   309.0,\n",
       "   294.0,\n",
       "   305.0,\n",
       "   285.0,\n",
       "   291.0,\n",
       "   266.0,\n",
       "   293.0,\n",
       "   282.0],\n",
       "  'fn': [169.0,\n",
       "   179.0,\n",
       "   136.0,\n",
       "   119.0,\n",
       "   161.0,\n",
       "   141.0,\n",
       "   123.0,\n",
       "   159.0,\n",
       "   119.0,\n",
       "   130.0,\n",
       "   166.0,\n",
       "   128.0,\n",
       "   139.0,\n",
       "   132.0,\n",
       "   110.0,\n",
       "   120.0,\n",
       "   104.0,\n",
       "   103.0,\n",
       "   105.0,\n",
       "   110.0],\n",
       "  'accuracy': [0.57543105,\n",
       "   0.5840517,\n",
       "   0.6325431,\n",
       "   0.6551724,\n",
       "   0.66056037,\n",
       "   0.66702586,\n",
       "   0.67349136,\n",
       "   0.63577586,\n",
       "   0.67133623,\n",
       "   0.67456895,\n",
       "   0.6314655,\n",
       "   0.6627155,\n",
       "   0.6821121,\n",
       "   0.66810346,\n",
       "   0.6648707,\n",
       "   0.68318963,\n",
       "   0.6778017,\n",
       "   0.6637931,\n",
       "   0.6864224,\n",
       "   0.66810346],\n",
       "  'precision': [0.5535714,\n",
       "   0.577551,\n",
       "   0.5940594,\n",
       "   0.6104651,\n",
       "   0.65701556,\n",
       "   0.6455696,\n",
       "   0.6421471,\n",
       "   0.62708336,\n",
       "   0.64092666,\n",
       "   0.64241165,\n",
       "   0.62473345,\n",
       "   0.62321794,\n",
       "   0.675,\n",
       "   0.6494024,\n",
       "   0.60818714,\n",
       "   0.66730404,\n",
       "   0.63414633,\n",
       "   0.62611806,\n",
       "   0.6490566,\n",
       "   0.630597],\n",
       "  'recall': [0.62276787,\n",
       "   0.61255413,\n",
       "   0.6880734,\n",
       "   0.7258065,\n",
       "   0.6469298,\n",
       "   0.68456376,\n",
       "   0.72421527,\n",
       "   0.65434784,\n",
       "   0.7361419,\n",
       "   0.70387244,\n",
       "   0.6383442,\n",
       "   0.7050691,\n",
       "   0.69978404,\n",
       "   0.7117904,\n",
       "   0.7393365,\n",
       "   0.74413645,\n",
       "   0.7647059,\n",
       "   0.77262694,\n",
       "   0.766147,\n",
       "   0.75446427],\n",
       "  'auc': [0.5823335,\n",
       "   0.6048437,\n",
       "   0.65762055,\n",
       "   0.6842269,\n",
       "   0.69224143,\n",
       "   0.6906426,\n",
       "   0.6899829,\n",
       "   0.66053045,\n",
       "   0.69140786,\n",
       "   0.7041684,\n",
       "   0.650782,\n",
       "   0.6959645,\n",
       "   0.69264734,\n",
       "   0.68085796,\n",
       "   0.69226164,\n",
       "   0.69748604,\n",
       "   0.6946609,\n",
       "   0.6796444,\n",
       "   0.6998875,\n",
       "   0.6911738],\n",
       "  'binary_crossentropy': [1.0627991,\n",
       "   2.0797808,\n",
       "   1.9329865,\n",
       "   1.9873818,\n",
       "   2.093855,\n",
       "   2.2527642,\n",
       "   2.1196537,\n",
       "   2.6089215,\n",
       "   2.398359,\n",
       "   2.3583999,\n",
       "   2.3734846,\n",
       "   2.1649797,\n",
       "   2.3588073,\n",
       "   2.5573897,\n",
       "   2.584437,\n",
       "   2.4013886,\n",
       "   2.5014594,\n",
       "   2.4850256,\n",
       "   2.313967,\n",
       "   2.5238519],\n",
       "  'val_loss': [0.25528839692987243,\n",
       "   0.2533653399039959,\n",
       "   0.25317171935377447,\n",
       "   0.2352503933783235,\n",
       "   0.23081169226046266,\n",
       "   0.20217850290495773,\n",
       "   0.19004818668653226,\n",
       "   0.2220761534468881,\n",
       "   0.2010679394006729,\n",
       "   0.14356249596538215,\n",
       "   0.28497548786730603,\n",
       "   0.19181030474860092,\n",
       "   0.23922306941501026,\n",
       "   0.2155156672514718,\n",
       "   0.20905045214398155,\n",
       "   0.21551808483641724,\n",
       "   0.2155219141779275,\n",
       "   0.24352918308356714,\n",
       "   0.2176810109923626,\n",
       "   0.23275545290831862],\n",
       "  'val_tp': [45.0,\n",
       "   112.0,\n",
       "   10.0,\n",
       "   120.0,\n",
       "   33.0,\n",
       "   50.0,\n",
       "   64.0,\n",
       "   127.0,\n",
       "   132.0,\n",
       "   95.0,\n",
       "   5.0,\n",
       "   143.0,\n",
       "   121.0,\n",
       "   132.0,\n",
       "   135.0,\n",
       "   132.0,\n",
       "   132.0,\n",
       "   119.0,\n",
       "   131.0,\n",
       "   124.0],\n",
       "  'val_fp': [18.0,\n",
       "   54.0,\n",
       "   6.0,\n",
       "   98.0,\n",
       "   13.0,\n",
       "   8.0,\n",
       "   27.0,\n",
       "   104.0,\n",
       "   87.0,\n",
       "   31.0,\n",
       "   0.0,\n",
       "   89.0,\n",
       "   111.0,\n",
       "   100.0,\n",
       "   97.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   113.0,\n",
       "   101.0,\n",
       "   108.0],\n",
       "  'val_tn': [79.0,\n",
       "   47.0,\n",
       "   99.0,\n",
       "   10.0,\n",
       "   89.0,\n",
       "   87.0,\n",
       "   80.0,\n",
       "   1.0,\n",
       "   11.0,\n",
       "   69.0,\n",
       "   95.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_fn': [90.0,\n",
       "   19.0,\n",
       "   117.0,\n",
       "   4.0,\n",
       "   97.0,\n",
       "   87.0,\n",
       "   61.0,\n",
       "   0.0,\n",
       "   2.0,\n",
       "   37.0,\n",
       "   132.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'val_accuracy': [0.5344828,\n",
       "   0.6853448,\n",
       "   0.4698276,\n",
       "   0.5603448,\n",
       "   0.5258621,\n",
       "   0.5905172,\n",
       "   0.62068963,\n",
       "   0.55172414,\n",
       "   0.6163793,\n",
       "   0.70689654,\n",
       "   0.43103448,\n",
       "   0.6163793,\n",
       "   0.5215517,\n",
       "   0.5689655,\n",
       "   0.58189654,\n",
       "   0.5689655,\n",
       "   0.5689655,\n",
       "   0.51293105,\n",
       "   0.5646552,\n",
       "   0.5344828],\n",
       "  'val_precision': [0.71428573,\n",
       "   0.67469877,\n",
       "   0.625,\n",
       "   0.5504587,\n",
       "   0.7173913,\n",
       "   0.86206895,\n",
       "   0.7032967,\n",
       "   0.5497835,\n",
       "   0.60273975,\n",
       "   0.75396824,\n",
       "   1.0,\n",
       "   0.6163793,\n",
       "   0.5215517,\n",
       "   0.5689655,\n",
       "   0.58189654,\n",
       "   0.5689655,\n",
       "   0.5689655,\n",
       "   0.51293105,\n",
       "   0.5646552,\n",
       "   0.5344828],\n",
       "  'val_recall': [0.33333334,\n",
       "   0.8549618,\n",
       "   0.07874016,\n",
       "   0.9677419,\n",
       "   0.25384617,\n",
       "   0.3649635,\n",
       "   0.512,\n",
       "   1.0,\n",
       "   0.98507464,\n",
       "   0.719697,\n",
       "   0.03649635,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_auc': [0.6629247,\n",
       "   0.6927292,\n",
       "   0.6901012,\n",
       "   0.61686087,\n",
       "   0.6694193,\n",
       "   0.665117,\n",
       "   0.67648596,\n",
       "   0.5988001,\n",
       "   0.5744746,\n",
       "   0.76875,\n",
       "   0.5182482,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5],\n",
       "  'val_binary_crossentropy': [0.6909372,\n",
       "   0.6753175,\n",
       "   0.8701927,\n",
       "   0.87846863,\n",
       "   1.9865911,\n",
       "   3.940261,\n",
       "   3.0398197,\n",
       "   3.45003,\n",
       "   3.0136344,\n",
       "   1.493276,\n",
       "   14.063618,\n",
       "   7.5196466,\n",
       "   6.0024753,\n",
       "   4.4467397,\n",
       "   4.9599147,\n",
       "   4.833425,\n",
       "   3.635309,\n",
       "   4.124314,\n",
       "   3.3968225,\n",
       "   3.711204],\n",
       "  'lr': [1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   5e-05,\n",
       "   5e-05,\n",
       "   5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   1.25e-05]}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = history.history[\"loss\"]\n",
    "val_loss_ = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
