{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=2 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.adjust_brightness(image, 0.2)\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.3)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelEncoder()\n",
    "# image_names = train_df[\"image_name\"].values\n",
    "# train_df[\"image_name\"] = lb.fit_transform(train_df[\"image_name\"].values)\n",
    "# train_df[\"target\"] = train_df[\"target\"].astype(\"int\")\n",
    "# train_df.head()\n",
    "# map_name_no = dict(zip(train_df[\"image_name\"], image_names))\n",
    "# y_train = train_df[\"target\"]\n",
    "# x_train = train_df[[\"image_name\"]]\n",
    "\n",
    "\n",
    "# over = SMOTE(random_state=45, sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# ppl = Pipeline(steps=steps)\n",
    "# x_train, y_train = ppl.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)\n",
    "# x_train[\"image_name\"] = x_train[\"image_name\"].apply(lambda x: map_name_no[x])\n",
    "# x_val[\"image_name\"] = x_val[\"image_name\"].apply(lambda x: map_name_no[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1401, 1), (351, 1), (1401,), (351,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74600639, 1.51623377])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: Tensor(\"conv2d_7/Identity:0\", shape=(None, 37, 37, 64), dtype=float32) (None, 37, 37, 64), refer: Tensor(\"up_sampling2d/Identity:0\", shape=(None, 36, 36, 80), dtype=float32) (None, 36, 36, 80)\n",
      "target: Tensor(\"conv2d_5/Identity:0\", shape=(None, 75, 75, 48), dtype=float32) (None, 75, 75, 48), refer: Tensor(\"up_sampling2d_1/Identity:0\", shape=(None, 72, 72, 256), dtype=float32) (None, 72, 72, 256)\n",
      "target: Tensor(\"conv2d_3/Identity:0\", shape=(None, 150, 150, 32), dtype=float32) (None, 150, 150, 32), refer: Tensor(\"up_sampling2d_2/Identity:0\", shape=(None, 144, 144, 192), dtype=float32) (None, 144, 144, 192)\n",
      "target: Tensor(\"conv2d_1/Identity:0\", shape=(None, 300, 300, 16), dtype=float32) (None, 300, 300, 16), refer: Tensor(\"up_sampling2d_3/Identity:0\", shape=(None, 288, 288, 192), dtype=float32) (None, 288, 288, 192)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 300, 300, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 300, 300, 16) 2320        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 150, 150, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150, 150, 16) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 32) 4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 32) 9248        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 75, 75, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 48)   13872       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 48)   20784       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 37, 37, 48)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 37, 37, 64)   27712       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 37, 37, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 18, 18, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 18, 18, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 18, 18, 80)   46160       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 18, 18, 80)   57680       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 36, 36, 80)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 36, 36, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 36, 36, 144)  0           up_sampling2d[0][0]              \n",
      "                                                                 cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 36, 36, 144)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 36, 36, 256)  332032      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 36, 36, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 72, 72, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 72, 72, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 304)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 72, 72, 304)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 192)  525504      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 192)  331968      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 144, 144, 192 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 144, 144, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144, 144, 224 0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 144, 144, 224 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 144, 144, 192 387264      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 144, 144, 192 331968      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 288, 288, 192 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 288, 288, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 288, 288, 208 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 288, 288, 208 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 288, 288, 64) 119872      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 288, 288, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 288, 288, 1)  65          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 82944)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          21233920    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 24,210,770\n",
      "Trainable params: 24,209,490\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_unet(input_layer, expansion_filters=64, expansion_kernel=(3,3), expansion_pool_size=(2,2),\n",
    "          contract_filters=64, contract_kernel=(3,3), contract_pool_size=(2,2)):\n",
    "    \n",
    "    #64\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_1)\n",
    "    mp_lvl_1 = MaxPooling2D(expansion_pool_size)(lvl_1)\n",
    "    mp_lvl_1 = Dropout(0.25)(mp_lvl_1)\n",
    "    \n",
    "    #128\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_1)\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_2)\n",
    "    mp_lvl_2 = MaxPooling2D(expansion_pool_size)(lvl_2)\n",
    "    mp_lvl_2 = Dropout(0.25)(mp_lvl_2)\n",
    "    \n",
    "    #256\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_2)\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_3)\n",
    "    mp_lvl_3 = MaxPooling2D(expansion_pool_size)(lvl_3)\n",
    "    mp_lvl_3 = Dropout(0.25)(mp_lvl_3)\n",
    "    \n",
    "    #512\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_3)\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_4)\n",
    "    mp_lvl_4 = MaxPooling2D(expansion_pool_size)(lvl_4)\n",
    "    mp_lvl_4 = Dropout(0.25)(mp_lvl_4)\n",
    "    \n",
    "    #1024\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_4)\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    \n",
    "    #d_lvl_4 = Conv2DTranspose(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    d_lvl_4 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(lvl_5)\n",
    "    ch, cw = get_crop_shape(lvl_4, d_lvl_4)\n",
    "    ccon_4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_4)\n",
    "    ucon_4 = concatenate([d_lvl_4, ccon_4])\n",
    "    ucon_4 = Dropout(0.25)(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    \n",
    "    #d_lvl_3 = Conv2DTranspose(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    d_lvl_3 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_4)\n",
    "    ch, cw = get_crop_shape(lvl_3, d_lvl_3)\n",
    "    ccon_3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_3)\n",
    "    ucon_3 = concatenate([d_lvl_3, ccon_3])\n",
    "    ucon_3 = Dropout(0.25)(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    \n",
    "    #d_lvl_2 = Conv2DTranspose(filters=contract_filters*2, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    d_lvl_2 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_3)\n",
    "    ch, cw = get_crop_shape(lvl_2, d_lvl_2)\n",
    "    ccon_2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_2)\n",
    "    ucon_2 = concatenate([d_lvl_2, ccon_2])\n",
    "    ucon_2 = Dropout(0.25)(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    \n",
    "    #d_lvl_1 = Conv2DTranspose(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    d_lvl_1 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_2)\n",
    "    ch, cw = get_crop_shape(lvl_1, d_lvl_1)\n",
    "    ccon_1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_1)\n",
    "    ucon_1 = concatenate([d_lvl_1, ccon_1])\n",
    "    ucon_1 = Dropout(0.25)(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    output = Conv2D(filters=1, kernel_size=(1,1), activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    flatten = Flatten()(output)\n",
    "    dense4 = Dense(256, activation='relu')(flatten)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    dense3 = Dense(256, activation='relu')(bn4)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense2 = Dense(128, activation='relu')(bn3)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense1 = Dense(1, activation=\"sigmoid\")(bn2)\n",
    "    model = Model(inputs=input_layer, outputs=dense1)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = model_unet(input_layer, expansion_filters=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x1f1f800ef88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 175 steps, validate for 43 steps\n",
      "Epoch 1/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.2101 - tp: 260.0000 - fp: 344.0000 - tn: 599.0000 - fn: 197.0000 - accuracy: 0.6136 - precision: 0.4305 - recall: 0.5689 - auc: 0.6481 - binary_crossentropy: 1.4534 - val_loss: 0.2634 - val_tp: 103.0000 - val_fp: 104.0000 - val_tn: 114.0000 - val_fn: 23.0000 - val_accuracy: 0.6308 - val_precision: 0.4976 - val_recall: 0.8175 - val_auc: 0.7194 - val_binary_crossentropy: 0.6729\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 175s 1s/step - loss: 0.1727 - tp: 290.0000 - fp: 277.0000 - tn: 660.0000 - fn: 173.0000 - accuracy: 0.6786 - precision: 0.5115 - recall: 0.6263 - auc: 0.7097 - binary_crossentropy: 1.6554 - val_loss: 0.1975 - val_tp: 46.0000 - val_fp: 24.0000 - val_tn: 191.0000 - val_fn: 83.0000 - val_accuracy: 0.6890 - val_precision: 0.6571 - val_recall: 0.3566 - val_auc: 0.7487 - val_binary_crossentropy: 0.6203\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 186s 1s/step - loss: 0.1595 - tp: 283.0000 - fp: 233.0000 - tn: 697.0000 - fn: 187.0000 - accuracy: 0.7000 - precision: 0.5484 - recall: 0.6021 - auc: 0.7043 - binary_crossentropy: 1.8629 - val_loss: 0.1345 - val_tp: 60.0000 - val_fp: 22.0000 - val_tn: 200.0000 - val_fn: 62.0000 - val_accuracy: 0.7558 - val_precision: 0.7317 - val_recall: 0.4918 - val_auc: 0.7992 - val_binary_crossentropy: 0.7876\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 190s 1s/step - loss: 0.1478 - tp: 291.0000 - fp: 232.0000 - tn: 712.0000 - fn: 165.0000 - accuracy: 0.7164 - precision: 0.5564 - recall: 0.6382 - auc: 0.7425 - binary_crossentropy: 1.7881 - val_loss: 0.3256 - val_tp: 120.0000 - val_fp: 224.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3488 - val_precision: 0.3488 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 8.0076\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 194s 1s/step - loss: 0.1437 - tp: 312.0000 - fp: 219.0000 - tn: 693.0000 - fn: 176.0000 - accuracy: 0.7179 - precision: 0.5876 - recall: 0.6393 - auc: 0.7516 - binary_crossentropy: 1.6989 - val_loss: 0.3176 - val_tp: 123.0000 - val_fp: 220.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3605 - val_precision: 0.3586 - val_recall: 1.0000 - val_auc: 0.6723 - val_binary_crossentropy: 4.6954\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 200s 1s/step - loss: 0.1479 - tp: 302.0000 - fp: 252.0000 - tn: 705.0000 - fn: 141.0000 - accuracy: 0.7193 - precision: 0.5451 - recall: 0.6817 - auc: 0.7458 - binary_crossentropy: 1.8754 - val_loss: 0.3198 - val_tp: 124.0000 - val_fp: 220.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3605 - val_precision: 0.3605 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 10.9978\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 197s 1s/step - loss: 0.1499 - tp: 285.0000 - fp: 235.0000 - tn: 709.0000 - fn: 171.0000 - accuracy: 0.7100 - precision: 0.5481 - recall: 0.6250 - auc: 0.7319 - binary_crossentropy: 2.0655 - val_loss: 0.3125 - val_tp: 129.0000 - val_fp: 215.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 15.6178\n",
      "Epoch 8/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1324 - tp: 303.0000 - fp: 204.0000 - tn: 734.0000 - fn: 151.0000 - accuracy: 0.7450 - precision: 0.5976 - recall: 0.6674 - auc: 0.7663 - binary_crossentropy: 1.8290\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "175/175 [==============================] - 197s 1s/step - loss: 0.1334 - tp: 304.0000 - fp: 206.0000 - tn: 736.0000 - fn: 154.0000 - accuracy: 0.7429 - precision: 0.5961 - recall: 0.6638 - auc: 0.7634 - binary_crossentropy: 1.8447 - val_loss: 0.1758 - val_tp: 111.0000 - val_fp: 85.0000 - val_tn: 138.0000 - val_fn: 10.0000 - val_accuracy: 0.7238 - val_precision: 0.5663 - val_recall: 0.9174 - val_auc: 0.8370 - val_binary_crossentropy: 1.9610\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 198s 1s/step - loss: 0.1460 - tp: 266.0000 - fp: 216.0000 - tn: 733.0000 - fn: 185.0000 - accuracy: 0.7136 - precision: 0.5519 - recall: 0.5898 - auc: 0.7190 - binary_crossentropy: 2.1070 - val_loss: 0.1307 - val_tp: 106.0000 - val_fp: 53.0000 - val_tn: 159.0000 - val_fn: 26.0000 - val_accuracy: 0.7703 - val_precision: 0.6667 - val_recall: 0.8030 - val_auc: 0.8162 - val_binary_crossentropy: 1.7474\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 198s 1s/step - loss: 0.1351 - tp: 310.0000 - fp: 213.0000 - tn: 716.0000 - fn: 161.0000 - accuracy: 0.7329 - precision: 0.5927 - recall: 0.6582 - auc: 0.7599 - binary_crossentropy: 2.0530 - val_loss: 0.1123 - val_tp: 93.0000 - val_fp: 39.0000 - val_tn: 178.0000 - val_fn: 34.0000 - val_accuracy: 0.7878 - val_precision: 0.7045 - val_recall: 0.7323 - val_auc: 0.8408 - val_binary_crossentropy: 1.3235\n",
      "Epoch 11/40\n",
      "175/175 [==============================] - 199s 1s/step - loss: 0.1388 - tp: 304.0000 - fp: 220.0000 - tn: 717.0000 - fn: 159.0000 - accuracy: 0.7293 - precision: 0.5802 - recall: 0.6566 - auc: 0.7587 - binary_crossentropy: 2.0579 - val_loss: 0.3238 - val_tp: 113.0000 - val_fp: 221.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.3459 - val_precision: 0.3383 - val_recall: 0.9658 - val_auc: 0.7155 - val_binary_crossentropy: 4.8306\n",
      "Epoch 12/40\n",
      "175/175 [==============================] - 198s 1s/step - loss: 0.1321 - tp: 321.0000 - fp: 203.0000 - tn: 721.0000 - fn: 155.0000 - accuracy: 0.7443 - precision: 0.6126 - recall: 0.6744 - auc: 0.7608 - binary_crossentropy: 1.9351 - val_loss: 0.3049 - val_tp: 126.0000 - val_fp: 214.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3779 - val_precision: 0.3706 - val_recall: 1.0000 - val_auc: 0.7762 - val_binary_crossentropy: 3.0915\n",
      "Epoch 13/40\n",
      "175/175 [==============================] - 190s 1s/step - loss: 0.1423 - tp: 283.0000 - fp: 222.0000 - tn: 717.0000 - fn: 178.0000 - accuracy: 0.7143 - precision: 0.5604 - recall: 0.6139 - auc: 0.7500 - binary_crossentropy: 2.1222 - val_loss: 0.2890 - val_tp: 117.0000 - val_fp: 209.0000 - val_tn: 15.0000 - val_fn: 3.0000 - val_accuracy: 0.3837 - val_precision: 0.3589 - val_recall: 0.9750 - val_auc: 0.7666 - val_binary_crossentropy: 1.2423\n",
      "Epoch 14/40\n",
      "175/175 [==============================] - 200s 1s/step - loss: 0.1337 - tp: 312.0000 - fp: 227.0000 - tn: 728.0000 - fn: 133.0000 - accuracy: 0.7429 - precision: 0.5788 - recall: 0.7011 - auc: 0.7676 - binary_crossentropy: 2.1296 - val_loss: 0.3096 - val_tp: 131.0000 - val_fp: 213.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3808 - val_precision: 0.3808 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 16.7940\n",
      "Epoch 15/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1375 - tp: 305.0000 - fp: 209.0000 - tn: 717.0000 - fn: 161.0000 - accuracy: 0.7342 - precision: 0.5934 - recall: 0.6545 - auc: 0.7543 - binary_crossentropy: 1.9642\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "175/175 [==============================] - 199s 1s/step - loss: 0.1371 - tp: 307.0000 - fp: 210.0000 - tn: 722.0000 - fn: 161.0000 - accuracy: 0.7350 - precision: 0.5938 - recall: 0.6560 - auc: 0.7552 - binary_crossentropy: 1.9568 - val_loss: 0.3343 - val_tp: 114.0000 - val_fp: 230.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3314 - val_precision: 0.3314 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 26.8222\n",
      "Epoch 16/40\n",
      "175/175 [==============================] - 187s 1s/step - loss: 0.1274 - tp: 314.0000 - fp: 194.0000 - tn: 744.0000 - fn: 148.0000 - accuracy: 0.7557 - precision: 0.6181 - recall: 0.6797 - auc: 0.7740 - binary_crossentropy: 1.7385 - val_loss: 0.3137 - val_tp: 114.0000 - val_fp: 225.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3459 - val_precision: 0.3363 - val_recall: 1.0000 - val_auc: 0.7977 - val_binary_crossentropy: 3.5030\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 191s 1s/step - loss: 0.1279 - tp: 311.0000 - fp: 196.0000 - tn: 736.0000 - fn: 157.0000 - accuracy: 0.7479 - precision: 0.6134 - recall: 0.6645 - auc: 0.7877 - binary_crossentropy: 1.7562 - val_loss: 0.2354 - val_tp: 100.0000 - val_fp: 114.0000 - val_tn: 113.0000 - val_fn: 17.0000 - val_accuracy: 0.6192 - val_precision: 0.4673 - val_recall: 0.8547 - val_auc: 0.7883 - val_binary_crossentropy: 1.9926\n",
      "Epoch 18/40\n",
      "175/175 [==============================] - 195s 1s/step - loss: 0.1226 - tp: 313.0000 - fp: 190.0000 - tn: 755.0000 - fn: 142.0000 - accuracy: 0.7629 - precision: 0.6223 - recall: 0.6879 - auc: 0.7977 - binary_crossentropy: 1.6264 - val_loss: 0.3047 - val_tp: 120.0000 - val_fp: 221.0000 - val_tn: 0.0000e+00 - val_fn: 3.0000 - val_accuracy: 0.3488 - val_precision: 0.3519 - val_recall: 0.9756 - val_auc: 0.8286 - val_binary_crossentropy: 2.3656\n",
      "Epoch 19/40\n",
      "175/175 [==============================] - 198s 1s/step - loss: 0.1234 - tp: 311.0000 - fp: 181.0000 - tn: 755.0000 - fn: 153.0000 - accuracy: 0.7614 - precision: 0.6321 - recall: 0.6703 - auc: 0.7984 - binary_crossentropy: 1.7571 - val_loss: 0.0972 - val_tp: 71.0000 - val_fp: 22.0000 - val_tn: 210.0000 - val_fn: 41.0000 - val_accuracy: 0.8169 - val_precision: 0.7634 - val_recall: 0.6339 - val_auc: 0.8433 - val_binary_crossentropy: 1.1745\n",
      "Epoch 20/40\n",
      "175/175 [==============================] - 177s 1s/step - loss: 0.1280 - tp: 315.0000 - fp: 201.0000 - tn: 744.0000 - fn: 140.0000 - accuracy: 0.7564 - precision: 0.6105 - recall: 0.6923 - auc: 0.7669 - binary_crossentropy: 1.8918 - val_loss: 0.2741 - val_tp: 114.0000 - val_fp: 180.0000 - val_tn: 47.0000 - val_fn: 3.0000 - val_accuracy: 0.4680 - val_precision: 0.3878 - val_recall: 0.9744 - val_auc: 0.7917 - val_binary_crossentropy: 3.1759\n",
      "Epoch 21/40\n",
      "175/175 [==============================] - 180s 1s/step - loss: 0.1228 - tp: 322.0000 - fp: 187.0000 - tn: 748.0000 - fn: 143.0000 - accuracy: 0.7643 - precision: 0.6326 - recall: 0.6925 - auc: 0.7930 - binary_crossentropy: 1.6709 - val_loss: 0.1507 - val_tp: 91.0000 - val_fp: 52.0000 - val_tn: 177.0000 - val_fn: 24.0000 - val_accuracy: 0.7791 - val_precision: 0.6364 - val_recall: 0.7913 - val_auc: 0.7795 - val_binary_crossentropy: 1.4906\n",
      "Epoch 22/40\n",
      "175/175 [==============================] - 197s 1s/step - loss: 0.1213 - tp: 323.0000 - fp: 191.0000 - tn: 750.0000 - fn: 136.0000 - accuracy: 0.7664 - precision: 0.6284 - recall: 0.7037 - auc: 0.7883 - binary_crossentropy: 1.6984 - val_loss: 0.3138 - val_tp: 125.0000 - val_fp: 212.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3837 - val_precision: 0.3709 - val_recall: 1.0000 - val_auc: 0.6682 - val_binary_crossentropy: 5.2250\n",
      "Epoch 23/40\n",
      "175/175 [==============================] - 182s 1s/step - loss: 0.1247 - tp: 301.0000 - fp: 186.0000 - tn: 768.0000 - fn: 145.0000 - accuracy: 0.7636 - precision: 0.6181 - recall: 0.6749 - auc: 0.7748 - binary_crossentropy: 1.8543 - val_loss: 0.3070 - val_tp: 117.0000 - val_fp: 207.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.3808 - val_precision: 0.3611 - val_recall: 0.9512 - val_auc: 0.6664 - val_binary_crossentropy: 4.3748\n",
      "Epoch 24/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1316 - tp: 308.0000 - fp: 172.0000 - tn: 728.0000 - fn: 184.0000 - accuracy: 0.7443 - precision: 0.6417 - recall: 0.6260 - auc: 0.7712 - binary_crossentropy: 1.8004\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "175/175 [==============================] - 199s 1s/step - loss: 0.1314 - tp: 310.0000 - fp: 173.0000 - tn: 733.0000 - fn: 184.0000 - accuracy: 0.7450 - precision: 0.6418 - recall: 0.6275 - auc: 0.7716 - binary_crossentropy: 1.8000 - val_loss: 0.1262 - val_tp: 89.0000 - val_fp: 41.0000 - val_tn: 179.0000 - val_fn: 35.0000 - val_accuracy: 0.7791 - val_precision: 0.6846 - val_recall: 0.7177 - val_auc: 0.8163 - val_binary_crossentropy: 1.2103\n",
      "Epoch 25/40\n",
      "175/175 [==============================] - 220s 1s/step - loss: 0.1216 - tp: 306.0000 - fp: 189.0000 - tn: 765.0000 - fn: 140.0000 - accuracy: 0.7650 - precision: 0.6182 - recall: 0.6861 - auc: 0.7918 - binary_crossentropy: 1.8021 - val_loss: 0.1732 - val_tp: 106.0000 - val_fp: 79.0000 - val_tn: 143.0000 - val_fn: 16.0000 - val_accuracy: 0.7238 - val_precision: 0.5730 - val_recall: 0.8689 - val_auc: 0.7977 - val_binary_crossentropy: 2.4602\n",
      "Epoch 26/40\n",
      "175/175 [==============================] - 195s 1s/step - loss: 0.1215 - tp: 316.0000 - fp: 181.0000 - tn: 747.0000 - fn: 156.0000 - accuracy: 0.7593 - precision: 0.6358 - recall: 0.6695 - auc: 0.7971 - binary_crossentropy: 1.6685 - val_loss: 0.1109 - val_tp: 66.0000 - val_fp: 22.0000 - val_tn: 199.0000 - val_fn: 57.0000 - val_accuracy: 0.7703 - val_precision: 0.7500 - val_recall: 0.5366 - val_auc: 0.8253 - val_binary_crossentropy: 1.1800\n",
      "Epoch 27/40\n",
      "175/175 [==============================] - 199s 1s/step - loss: 0.1215 - tp: 321.0000 - fp: 189.0000 - tn: 747.0000 - fn: 143.0000 - accuracy: 0.7629 - precision: 0.6294 - recall: 0.6918 - auc: 0.7915 - binary_crossentropy: 1.7815 - val_loss: 0.1453 - val_tp: 58.0000 - val_fp: 21.0000 - val_tn: 190.0000 - val_fn: 75.0000 - val_accuracy: 0.7209 - val_precision: 0.7342 - val_recall: 0.4361 - val_auc: 0.6967 - val_binary_crossentropy: 1.3974\n",
      "Epoch 28/40\n",
      "175/175 [==============================] - 199s 1s/step - loss: 0.1146 - tp: 324.0000 - fp: 170.0000 - tn: 768.0000 - fn: 138.0000 - accuracy: 0.7800 - precision: 0.6559 - recall: 0.7013 - auc: 0.8070 - binary_crossentropy: 1.6641 - val_loss: 0.1095 - val_tp: 91.0000 - val_fp: 36.0000 - val_tn: 182.0000 - val_fn: 35.0000 - val_accuracy: 0.7936 - val_precision: 0.7165 - val_recall: 0.7222 - val_auc: 0.8398 - val_binary_crossentropy: 1.0079\n",
      "Epoch 29/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1192 - tp: 316.0000 - fp: 186.0000 - tn: 752.0000 - fn: 138.0000 - accuracy: 0.7672 - precision: 0.6295 - recall: 0.6960 - auc: 0.7999 - binary_crossentropy: 1.7265\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "175/175 [==============================] - 206s 1s/step - loss: 0.1196 - tp: 318.0000 - fp: 187.0000 - tn: 755.0000 - fn: 140.0000 - accuracy: 0.7664 - precision: 0.6297 - recall: 0.6943 - auc: 0.7981 - binary_crossentropy: 1.7331 - val_loss: 0.1196 - val_tp: 64.0000 - val_fp: 30.0000 - val_tn: 197.0000 - val_fn: 53.0000 - val_accuracy: 0.7587 - val_precision: 0.6809 - val_recall: 0.5470 - val_auc: 0.8134 - val_binary_crossentropy: 1.1143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1f83f4cc8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373/1373 [==============================] - 855s 623ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_unet = model.predict(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05055937],\n",
       "       [0.00483434],\n",
       "       [0.00292812],\n",
       "       ...,\n",
       "       [0.00957957],\n",
       "       [0.00368847],\n",
       "       [0.6064426 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = history.history[\"loss\"]\n",
    "val_loss_ = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (11,) and (29,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1b4b1d511041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2761\u001b[0m     return gca().plot(\n\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2763\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \"\"\"\n\u001b[0;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (11,) and (29,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss_, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_, 'b', label=\"validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_vgg16():\n",
    "    model_vgg16 = VGG16(weights=\"imagenet\", include_top=False,\n",
    "                        input_shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
    "    for layer in model_vgg16.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    flat = Flatten()(model_vgg16.output)\n",
    "    output = Dense(1, activation=\"sigmoid\")(flat)\n",
    "    model = Model(model_vgg16.input, outputs=output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 41473     \n",
      "=================================================================\n",
      "Total params: 14,756,161\n",
      "Trainable params: 7,120,897\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_ = model_vgg16()\n",
    "model_chkpt_vgg16 = ModelCheckpoint(filepath=\"best_vgg16.h5\")\n",
    "model_vgg16_.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-04), loss=dice_loss, metrics=[METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 175 steps, validate for 43 steps\n",
      "Epoch 1/40\n",
      "175/175 [==============================] - 124s 707ms/step - loss: 0.1670 - tp: 2.0000 - fp: 4.0000 - tn: 934.0000 - fn: 460.0000 - accuracy: 0.6686 - precision: 0.3333 - recall: 0.0043 - auc: 0.4996 - binary_crossentropy: 11.2495 - val_loss: 0.1555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 237.0000 - val_fn: 107.0000 - val_accuracy: 0.6890 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 11.3679\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 119s 678ms/step - loss: 0.1721 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 918.0000 - fn: 482.0000 - accuracy: 0.6557 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.5956 - val_loss: 0.1831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 218.0000 - val_fn: 126.0000 - val_accuracy: 0.6337 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.6512\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 126s 717ms/step - loss: 0.1543 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 968.0000 - fn: 432.0000 - accuracy: 0.6914 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 11.2506 - val_loss: 0.1759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 223.0000 - val_fn: 121.0000 - val_accuracy: 0.6483 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 12.9342\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 137s 785ms/step - loss: 0.1671 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 932.0000 - fn: 468.0000 - accuracy: 0.6657 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.3951 - val_loss: 0.1875 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 215.0000 - val_fn: 129.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.7112\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 132s 753ms/step - loss: 0.1643 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 940.0000 - fn: 460.0000 - accuracy: 0.6714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.0067 - val_loss: 0.1831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 218.0000 - val_fn: 126.0000 - val_accuracy: 0.6337 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.3362\n",
      "Epoch 6/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1656 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 931.0000 - fn: 461.0000 - accuracy: 0.6688 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.1827\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "175/175 [==============================] - 129s 739ms/step - loss: 0.1657 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 936.0000 - fn: 464.0000 - accuracy: 0.6686 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.1953 - val_loss: 0.1846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 217.0000 - val_fn: 127.0000 - val_accuracy: 0.6308 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.5233\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 182s 1s/step - loss: 0.1618 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 947.0000 - fn: 453.0000 - accuracy: 0.6764 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 11.9293 - val_loss: 0.1991 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 207.0000 - val_fn: 137.0000 - val_accuracy: 0.6017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 14.4498\n",
      "Epoch 8/40\n",
      "175/175 [==============================] - 125s 713ms/step - loss: 0.1696 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 925.0000 - fn: 475.0000 - accuracy: 0.6607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.3764 - val_loss: 0.1730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 225.0000 - val_fn: 119.0000 - val_accuracy: 0.6541 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 12.8447\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 140s 801ms/step - loss: 0.1686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 928.0000 - fn: 472.0000 - accuracy: 0.6629 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.4145 - val_loss: 0.1831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 218.0000 - val_fn: 126.0000 - val_accuracy: 0.6337 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.2731\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 0.1557 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 964.0000 - fn: 436.0000 - accuracy: 0.6886 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 11.4563 - val_loss: 0.1657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 230.0000 - val_fn: 114.0000 - val_accuracy: 0.6686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 12.2378\n",
      "Epoch 11/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 905.0000 - fn: 487.0000 - accuracy: 0.6501 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.8787 ETA: 1s - loss: 0.1743 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 865.0000 - fn: 463.0000 - accuracy: 0.6514 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_cross\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "175/175 [==============================] - 128s 734ms/step - loss: 0.1743 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 912.0000 - fn: 488.0000 - accuracy: 0.6514 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - binary_crossentropy: 12.8343 - val_loss: 0.1817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 219.0000 - val_fn: 125.0000 - val_accuracy: 0.6366 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_crossentropy: 13.2805\n"
     ]
    }
   ],
   "source": [
    "history = model_vgg16_.fit(train_dataset, epochs=EPOCHS, callbacks=[lr,es, model_chkpt],\n",
    "                           steps_per_epoch = x_train.shape[0]//BATCH_SIZE, \n",
    "                           validation_data=val_dataset,\n",
    "                           validation_steps=x_val.shape[0]//BATCH_SIZE, class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373/1373 [==============================] - 182s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_vgg16 = model_vgg16_.predict(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = (pred_unet + pred_vgg16)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.025280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.002417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.001107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.049588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.018377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>0.004790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.001844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.303221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "0      ISIC_0052060  0.025280\n",
       "1      ISIC_0052349  0.002417\n",
       "2      ISIC_0058510  0.001464\n",
       "3      ISIC_0073313  0.001107\n",
       "4      ISIC_0073502  0.049588\n",
       "...             ...       ...\n",
       "10977  ISIC_9992485  0.002319\n",
       "10978  ISIC_9996992  0.018377\n",
       "10979  ISIC_9997917  0.004790\n",
       "10980  ISIC_9998234  0.001844\n",
       "10981  ISIC_9999302  0.303221\n",
       "\n",
       "[10982 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"unet_vgg16_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
