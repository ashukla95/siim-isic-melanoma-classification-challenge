{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=2 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.adjust_brightness(image, 0.2)\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.3)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelEncoder()\n",
    "# image_names = train_df[\"image_name\"].values\n",
    "# train_df[\"image_name\"] = lb.fit_transform(train_df[\"image_name\"].values)\n",
    "# train_df[\"target\"] = train_df[\"target\"].astype(\"int\")\n",
    "# train_df.head()\n",
    "# map_name_no = dict(zip(train_df[\"image_name\"], image_names))\n",
    "# y_train = train_df[\"target\"]\n",
    "# x_train = train_df[[\"image_name\"]]\n",
    "\n",
    "\n",
    "# over = SMOTE(random_state=45, sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# ppl = Pipeline(steps=steps)\n",
    "# x_train, y_train = ppl.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)\n",
    "# x_train[\"image_name\"] = x_train[\"image_name\"].apply(lambda x: map_name_no[x])\n",
    "# x_val[\"image_name\"] = x_val[\"image_name\"].apply(lambda x: map_name_no[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crfn(input_layer):\n",
    "    \n",
    "    # block - 1\n",
    "    conv1 = Conv2D(filters=16*(2**0), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv1\")(input_layer)\n",
    "    conv2 = Conv2D(filters=16*(2**0), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv2\")(conv1)\n",
    "    \n",
    "    # blovk - 2\n",
    "    conv3 = Conv2D(filters=16*(2**1), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv3\")(conv2)\n",
    "    conv4 = Conv2D(filters=16*(2**1), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv4\")(conv3)\n",
    "    \n",
    "    # block - 3\n",
    "    conv5 = Conv2D(filters=16*(2**2), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv5\")(conv4)\n",
    "    conv6 = Conv2D(filters=16*(2**2), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv6\")(conv5)\n",
    "    conv7 = Conv2D(filters=16*(2**2), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv7\")(conv6)\n",
    "    \n",
    "    # block - 4\n",
    "    conv8 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv8\")(conv7)\n",
    "    conv9 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv9\")(conv8)\n",
    "    conv10 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv10\")(conv9)\n",
    "    \n",
    "    # block - 5\n",
    "    conv11 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv11\")(conv10)\n",
    "    conv12 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv12\")(conv11)\n",
    "    conv13 = Conv2D(filters=16*(2**3), kernel_size=(3,3), activation=\"relu\", padding=\"same\", name=\"conv13\")(conv12)\n",
    "    \n",
    "    #block - 6\n",
    "    conv14 = Conv2D(filters=16*(2**4), kernel_size=(7,7), activation=\"relu\", padding=\"same\", name=\"conv14\")(conv13)\n",
    "    dr1 = Dropout(0.5)(conv14)\n",
    "    conv15 = Conv2D(filters=16*(2**4), kernel_size=(1,1), activation=\"relu\", padding=\"same\", name=\"conv15\")(dr1)\n",
    "    dr2 = Dropout(0.5)(conv15)\n",
    "    conv16 = Conv2D(filters=2, kernel_size=(1,1), activation=\"relu\", padding=\"same\", name=\"conv16\")(dr2)\n",
    "    \n",
    "    flatten_ = Flatten()(conv16)\n",
    "    dense_ = Dense(1, activation=\"sigmoid\")(flatten_)\n",
    "    model = Model(inputs = input_layer, outputs = dense_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model_crfn = get_crfn(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crfn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crfn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=BinaryCrossentropy(from_logits=True), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_crfn.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
