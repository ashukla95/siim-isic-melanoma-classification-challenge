{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=2 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "#image = tf.cast(image, tf.float32)/255.0\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    r_crop = np.random.uniform(low = 0.4, high = 1.0)\n",
    "    r_rsize = np.random.uniform(low = 0.8, high = 1.2)\n",
    "    image = tf.image.random_crop(image, (int(r_crop*IMG_HEIGHT), int(r_crop*IMG_WIDTH), 3))\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.keras.preprocessing.image.random_shear(image, 20)\n",
    "    image = tf.image.resize(image, (int(r_rsize*IMG_HEIGHT), int(r_rsize*IMG_WIDTH), 3), preserve_aspect_ratio=True)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_brightness(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "#     image = tf.image.rgb_to_hsv(image)\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.adjust_brightness(image, 0.2)\n",
    "#     image = tf.image.rot90(image)\n",
    "#     image = tf.image.central_crop(image, central_fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_unet(input_layer, expansion_filters=64, expansion_kernel=(3,3), expansion_pool_size=(2,2),\n",
    "          contract_filters=64, contract_kernel=(3,3), contract_pool_size=(2,2)):\n",
    "    \n",
    "    #64\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_1)\n",
    "    mp_lvl_1 = MaxPooling2D(expansion_pool_size)(lvl_1)\n",
    "    mp_lvl_1 = Dropout(0.25)(mp_lvl_1)\n",
    "    \n",
    "    #128\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_1)\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_2)\n",
    "    mp_lvl_2 = MaxPooling2D(expansion_pool_size)(lvl_2)\n",
    "    mp_lvl_2 = Dropout(0.25)(mp_lvl_2)\n",
    "    \n",
    "    #256\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_2)\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_3)\n",
    "    mp_lvl_3 = MaxPooling2D(expansion_pool_size)(lvl_3)\n",
    "    mp_lvl_3 = Dropout(0.25)(mp_lvl_3)\n",
    "    \n",
    "    #512\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_3)\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_4)\n",
    "    mp_lvl_4 = MaxPooling2D(expansion_pool_size)(lvl_4)\n",
    "    mp_lvl_4 = Dropout(0.25)(mp_lvl_4)\n",
    "    \n",
    "    #1024\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_4)\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    \n",
    "    #d_lvl_4 = Conv2DTranspose(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    d_lvl_4 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(lvl_5)\n",
    "    ch, cw = get_crop_shape(lvl_4, d_lvl_4)\n",
    "    ccon_4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_4)\n",
    "    ucon_4 = concatenate([d_lvl_4, ccon_4])\n",
    "    ucon_4 = Dropout(0.25)(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    \n",
    "    #d_lvl_3 = Conv2DTranspose(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    d_lvl_3 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_4)\n",
    "    ch, cw = get_crop_shape(lvl_3, d_lvl_3)\n",
    "    ccon_3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_3)\n",
    "    ucon_3 = concatenate([d_lvl_3, ccon_3])\n",
    "    ucon_3 = Dropout(0.25)(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    \n",
    "    #d_lvl_2 = Conv2DTranspose(filters=contract_filters*2, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    d_lvl_2 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_3)\n",
    "    ch, cw = get_crop_shape(lvl_2, d_lvl_2)\n",
    "    ccon_2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_2)\n",
    "    ucon_2 = concatenate([d_lvl_2, ccon_2])\n",
    "    ucon_2 = Dropout(0.25)(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    \n",
    "    #d_lvl_1 = Conv2DTranspose(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    d_lvl_1 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_2)\n",
    "    ch, cw = get_crop_shape(lvl_1, d_lvl_1)\n",
    "    ccon_1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_1)\n",
    "    ucon_1 = concatenate([d_lvl_1, ccon_1])\n",
    "    ucon_1 = Dropout(0.25)(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    output = Conv2D(filters=1, kernel_size=(1,1), activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    flatten = Flatten()(output)\n",
    "    dense4 = Dense(512, activation='relu')(flatten)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    dense3 = Dense(256, activation='relu')(bn4)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense2 = Dense(128, activation='relu')(bn3)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense1 = Dense(1, activation=\"sigmoid\")(bn2)\n",
    "    model = Model(inputs=input_layer, outputs=dense1)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = model_unet(input_layer, expansion_filters=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"dice_loss_unet_2d_images_hsv_augment_equal_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = history.history[\"loss\"]\n",
    "val_loss_ = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
