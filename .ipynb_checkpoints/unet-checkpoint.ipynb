{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=1 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.adjust_brightness(image, 0.2)\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.3)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelEncoder()\n",
    "# image_names = train_df[\"image_name\"].values\n",
    "# train_df[\"image_name\"] = lb.fit_transform(train_df[\"image_name\"].values)\n",
    "# train_df[\"target\"] = train_df[\"target\"].astype(\"int\")\n",
    "# train_df.head()\n",
    "# map_name_no = dict(zip(train_df[\"image_name\"], image_names))\n",
    "# y_train = train_df[\"target\"]\n",
    "# x_train = train_df[[\"image_name\"]]\n",
    "\n",
    "\n",
    "# over = SMOTE(random_state=45, sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# ppl = Pipeline(steps=steps)\n",
    "# x_train, y_train = ppl.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)\n",
    "# x_train[\"image_name\"] = x_train[\"image_name\"].apply(lambda x: map_name_no[x])\n",
    "# x_val[\"image_name\"] = x_val[\"image_name\"].apply(lambda x: map_name_no[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1401, 1), (351, 1), (1401,), (351,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74600639, 1.51623377])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: Tensor(\"conv2d_7/Identity:0\", shape=(None, 37, 37, 64), dtype=float32) (None, 37, 37, 64), refer: Tensor(\"up_sampling2d/Identity:0\", shape=(None, 36, 36, 80), dtype=float32) (None, 36, 36, 80)\n",
      "target: Tensor(\"conv2d_5/Identity:0\", shape=(None, 75, 75, 48), dtype=float32) (None, 75, 75, 48), refer: Tensor(\"up_sampling2d_1/Identity:0\", shape=(None, 72, 72, 256), dtype=float32) (None, 72, 72, 256)\n",
      "target: Tensor(\"conv2d_3/Identity:0\", shape=(None, 150, 150, 32), dtype=float32) (None, 150, 150, 32), refer: Tensor(\"up_sampling2d_2/Identity:0\", shape=(None, 144, 144, 192), dtype=float32) (None, 144, 144, 192)\n",
      "target: Tensor(\"conv2d_1/Identity:0\", shape=(None, 300, 300, 16), dtype=float32) (None, 300, 300, 16), refer: Tensor(\"up_sampling2d_3/Identity:0\", shape=(None, 288, 288, 192), dtype=float32) (None, 288, 288, 192)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 300, 300, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 300, 300, 16) 2320        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 150, 150, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150, 150, 16) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 32) 4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 32) 9248        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 75, 75, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 48)   13872       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 48)   20784       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 37, 37, 48)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 37, 37, 64)   27712       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 37, 37, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 18, 18, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 18, 18, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 18, 18, 80)   46160       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 18, 18, 80)   57680       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 36, 36, 80)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 36, 36, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 36, 36, 144)  0           up_sampling2d[0][0]              \n",
      "                                                                 cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 36, 36, 144)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 36, 36, 256)  332032      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 36, 36, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 72, 72, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 72, 72, 48)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 304)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 72, 72, 304)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 192)  525504      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 192)  331968      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 144, 144, 192 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 144, 144, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144, 144, 224 0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 144, 144, 224 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 144, 144, 192 387264      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 144, 144, 192 331968      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 288, 288, 192 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 288, 288, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 288, 288, 208 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 288, 288, 208 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 288, 288, 64) 119872      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 288, 288, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 288, 288, 1)  65          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 82944)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          21233920    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 24,210,770\n",
      "Trainable params: 24,209,490\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_unet(input_layer, expansion_filters=64, expansion_kernel=(3,3), expansion_pool_size=(2,2),\n",
    "          contract_filters=64, contract_kernel=(3,3), contract_pool_size=(2,2)):\n",
    "    \n",
    "    #64\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_1)\n",
    "    mp_lvl_1 = MaxPooling2D(expansion_pool_size)(lvl_1)\n",
    "    mp_lvl_1 = Dropout(0.25)(mp_lvl_1)\n",
    "    \n",
    "    #128\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_1)\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_2)\n",
    "    mp_lvl_2 = MaxPooling2D(expansion_pool_size)(lvl_2)\n",
    "    mp_lvl_2 = Dropout(0.25)(mp_lvl_2)\n",
    "    \n",
    "    #256\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_2)\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_3)\n",
    "    mp_lvl_3 = MaxPooling2D(expansion_pool_size)(lvl_3)\n",
    "    mp_lvl_3 = Dropout(0.25)(mp_lvl_3)\n",
    "    \n",
    "    #512\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_3)\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_4)\n",
    "    mp_lvl_4 = MaxPooling2D(expansion_pool_size)(lvl_4)\n",
    "    mp_lvl_4 = Dropout(0.25)(mp_lvl_4)\n",
    "    \n",
    "    #1024\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_4)\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    \n",
    "    #d_lvl_4 = Conv2DTranspose(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    d_lvl_4 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(lvl_5)\n",
    "    ch, cw = get_crop_shape(lvl_4, d_lvl_4)\n",
    "    ccon_4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_4)\n",
    "    ucon_4 = concatenate([d_lvl_4, ccon_4])\n",
    "    ucon_4 = Dropout(0.25)(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    \n",
    "    #d_lvl_3 = Conv2DTranspose(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    d_lvl_3 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_4)\n",
    "    ch, cw = get_crop_shape(lvl_3, d_lvl_3)\n",
    "    ccon_3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_3)\n",
    "    ucon_3 = concatenate([d_lvl_3, ccon_3])\n",
    "    ucon_3 = Dropout(0.25)(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    \n",
    "    #d_lvl_2 = Conv2DTranspose(filters=contract_filters*2, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    d_lvl_2 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_3)\n",
    "    ch, cw = get_crop_shape(lvl_2, d_lvl_2)\n",
    "    ccon_2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_2)\n",
    "    ucon_2 = concatenate([d_lvl_2, ccon_2])\n",
    "    ucon_2 = Dropout(0.25)(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    \n",
    "    #d_lvl_1 = Conv2DTranspose(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    d_lvl_1 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_2)\n",
    "    ch, cw = get_crop_shape(lvl_1, d_lvl_1)\n",
    "    ccon_1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_1)\n",
    "    ucon_1 = concatenate([d_lvl_1, ccon_1])\n",
    "    ucon_1 = Dropout(0.25)(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    output = Conv2D(filters=1, kernel_size=(1,1), activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    flatten = Flatten()(output)\n",
    "    dense4 = Dense(256, activation='relu')(flatten)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    dense3 = Dense(256, activation='relu')(bn4)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense2 = Dense(128, activation='relu')(bn3)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense1 = Dense(1, activation=\"sigmoid\")(bn2)\n",
    "    model = Model(inputs=input_layer, outputs=dense1)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = model_unet(input_layer, expansion_filters=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x14454688e48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 175 steps, validate for 43 steps\n",
      "Epoch 1/40\n",
      "175/175 [==============================] - 212s 1s/step - loss: 0.1833 - tp: 323.0000 - fp: 364.0000 - tn: 579.0000 - fn: 134.0000 - accuracy: 0.6443 - precision: 0.4702 - recall: 0.7068 - auc: 0.7171 - binary_crossentropy: 1.6053 - val_loss: 0.2420 - val_tp: 101.0000 - val_fp: 85.0000 - val_tn: 147.0000 - val_fn: 11.0000 - val_accuracy: 0.7209 - val_precision: 0.5430 - val_recall: 0.9018 - val_auc: 0.7724 - val_binary_crossentropy: 0.7445\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 173s 991ms/step - loss: 0.1605 - tp: 336.0000 - fp: 298.0000 - tn: 635.0000 - fn: 131.0000 - accuracy: 0.6936 - precision: 0.5300 - recall: 0.7195 - auc: 0.7326 - binary_crossentropy: 1.8517 - val_loss: 0.3183 - val_tp: 125.0000 - val_fp: 219.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3634 - val_precision: 0.3634 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 8.0963\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 176s 1s/step - loss: 0.1489 - tp: 341.0000 - fp: 277.0000 - tn: 662.0000 - fn: 120.0000 - accuracy: 0.7164 - precision: 0.5518 - recall: 0.7397 - auc: 0.7526 - binary_crossentropy: 1.7456 - val_loss: 0.3241 - val_tp: 121.0000 - val_fp: 223.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3517 - val_precision: 0.3517 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 10.5959\n",
      "Epoch 4/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1493 - tp: 300.0000 - fp: 242.0000 - tn: 695.0000 - fn: 155.0000 - accuracy: 0.7148 - precision: 0.5535 - recall: 0.6593 - auc: 0.7275 - binary_crossentropy: 2.0284\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "175/175 [==============================] - 178s 1s/step - loss: 0.1495 - tp: 303.0000 - fp: 242.0000 - tn: 697.0000 - fn: 158.0000 - accuracy: 0.7143 - precision: 0.5560 - recall: 0.6573 - auc: 0.7271 - binary_crossentropy: 2.0277 - val_loss: 0.3299 - val_tp: 117.0000 - val_fp: 227.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3401 - val_precision: 0.3401 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 12.7139\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 176s 1s/step - loss: 0.1395 - tp: 314.0000 - fp: 217.0000 - tn: 713.0000 - fn: 156.0000 - accuracy: 0.7336 - precision: 0.5913 - recall: 0.6681 - auc: 0.7405 - binary_crossentropy: 1.9699 - val_loss: 0.3248 - val_tp: 120.0000 - val_fp: 224.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3488 - val_precision: 0.3488 - val_recall: 1.0000 - val_auc: 0.6854 - val_binary_crossentropy: 5.9597\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 178s 1s/step - loss: 0.1389 - tp: 300.0000 - fp: 217.0000 - tn: 727.0000 - fn: 156.0000 - accuracy: 0.7336 - precision: 0.5803 - recall: 0.6579 - auc: 0.7553 - binary_crossentropy: 1.8779 - val_loss: 0.2505 - val_tp: 122.0000 - val_fp: 148.0000 - val_tn: 72.0000 - val_fn: 2.0000 - val_accuracy: 0.5640 - val_precision: 0.4519 - val_recall: 0.9839 - val_auc: 0.7893 - val_binary_crossentropy: 3.4186\n",
      "Epoch 7/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1349 - tp: 300.0000 - fp: 213.0000 - tn: 734.0000 - fn: 145.0000 - accuracy: 0.7428 - precision: 0.5848 - recall: 0.6742 - auc: 0.7650 - binary_crossentropy: 1.7689\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "175/175 [==============================] - 174s 997ms/step - loss: 0.1355 - tp: 301.0000 - fp: 216.0000 - tn: 737.0000 - fn: 146.0000 - accuracy: 0.7414 - precision: 0.5822 - recall: 0.6734 - auc: 0.7642 - binary_crossentropy: 1.7699 - val_loss: 0.3270 - val_tp: 108.0000 - val_fp: 229.0000 - val_tn: 4.0000 - val_fn: 3.0000 - val_accuracy: 0.3256 - val_precision: 0.3205 - val_recall: 0.9730 - val_auc: 0.7389 - val_binary_crossentropy: 5.9383\n",
      "Epoch 8/40\n",
      "175/175 [==============================] - 178s 1s/step - loss: 0.1339 - tp: 305.0000 - fp: 204.0000 - tn: 731.0000 - fn: 160.0000 - accuracy: 0.7400 - precision: 0.5992 - recall: 0.6559 - auc: 0.7504 - binary_crossentropy: 2.0506 - val_loss: 0.3015 - val_tp: 114.0000 - val_fp: 206.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.3953 - val_precision: 0.3562 - val_recall: 0.9828 - val_auc: 0.7541 - val_binary_crossentropy: 6.0467\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 179s 1s/step - loss: 0.1356 - tp: 302.0000 - fp: 202.0000 - tn: 728.0000 - fn: 168.0000 - accuracy: 0.7357 - precision: 0.5992 - recall: 0.6426 - auc: 0.7636 - binary_crossentropy: 1.8670 - val_loss: 0.1205 - val_tp: 112.0000 - val_fp: 58.0000 - val_tn: 156.0000 - val_fn: 18.0000 - val_accuracy: 0.7791 - val_precision: 0.6588 - val_recall: 0.8615 - val_auc: 0.8337 - val_binary_crossentropy: 2.0323\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 175s 998ms/step - loss: 0.1320 - tp: 298.0000 - fp: 189.0000 - tn: 744.0000 - fn: 169.0000 - accuracy: 0.7443 - precision: 0.6119 - recall: 0.6381 - auc: 0.7703 - binary_crossentropy: 1.8275 - val_loss: 0.3102 - val_tp: 123.0000 - val_fp: 213.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.3721 - val_precision: 0.3661 - val_recall: 0.9762 - val_auc: 0.7027 - val_binary_crossentropy: 5.3668\n",
      "Epoch 11/40\n",
      "175/175 [==============================] - 177s 1s/step - loss: 0.1300 - tp: 322.0000 - fp: 209.0000 - tn: 730.0000 - fn: 139.0000 - accuracy: 0.7514 - precision: 0.6064 - recall: 0.6985 - auc: 0.7782 - binary_crossentropy: 1.7792 - val_loss: 0.1440 - val_tp: 115.0000 - val_fp: 59.0000 - val_tn: 155.0000 - val_fn: 15.0000 - val_accuracy: 0.7849 - val_precision: 0.6609 - val_recall: 0.8846 - val_auc: 0.8358 - val_binary_crossentropy: 1.6092\n",
      "Epoch 12/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1191 - tp: 332.0000 - fp: 187.0000 - tn: 745.0000 - fn: 128.0000 - accuracy: 0.7737 - precision: 0.6397 - recall: 0.7217 - auc: 0.8074 - binary_crossentropy: 1.6080\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "175/175 [==============================] - 184s 1s/step - loss: 0.1192 - tp: 332.0000 - fp: 189.0000 - tn: 751.0000 - fn: 128.0000 - accuracy: 0.7736 - precision: 0.6372 - recall: 0.7217 - auc: 0.8070 - binary_crossentropy: 1.6174 - val_loss: 0.2841 - val_tp: 125.0000 - val_fp: 202.0000 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.4012 - val_precision: 0.3823 - val_recall: 0.9690 - val_auc: 0.7679 - val_binary_crossentropy: 3.8484\n",
      "Epoch 13/40\n",
      "175/175 [==============================] - 173s 987ms/step - loss: 0.1238 - tp: 315.0000 - fp: 178.0000 - tn: 755.0000 - fn: 152.0000 - accuracy: 0.7643 - precision: 0.6389 - recall: 0.6745 - auc: 0.7824 - binary_crossentropy: 1.7174 - val_loss: 0.2271 - val_tp: 121.0000 - val_fp: 123.0000 - val_tn: 95.0000 - val_fn: 5.0000 - val_accuracy: 0.6279 - val_precision: 0.4959 - val_recall: 0.9603 - val_auc: 0.8011 - val_binary_crossentropy: 3.2987\n",
      "Epoch 14/40\n",
      "175/175 [==============================] - 169s 965ms/step - loss: 0.1252 - tp: 311.0000 - fp: 206.0000 - tn: 750.0000 - fn: 133.0000 - accuracy: 0.7579 - precision: 0.6015 - recall: 0.7005 - auc: 0.7915 - binary_crossentropy: 1.6970 - val_loss: 0.1118 - val_tp: 90.0000 - val_fp: 43.0000 - val_tn: 184.0000 - val_fn: 27.0000 - val_accuracy: 0.7965 - val_precision: 0.6767 - val_recall: 0.7692 - val_auc: 0.8188 - val_binary_crossentropy: 1.6584\n",
      "Epoch 15/40\n",
      "175/175 [==============================] - 167s 957ms/step - loss: 0.1245 - tp: 317.0000 - fp: 175.0000 - tn: 753.0000 - fn: 155.0000 - accuracy: 0.7643 - precision: 0.6443 - recall: 0.6716 - auc: 0.7889 - binary_crossentropy: 1.6898 - val_loss: 0.2758 - val_tp: 115.0000 - val_fp: 178.0000 - val_tn: 42.0000 - val_fn: 9.0000 - val_accuracy: 0.4564 - val_precision: 0.3925 - val_recall: 0.9274 - val_auc: 0.7699 - val_binary_crossentropy: 3.2732\n",
      "Epoch 16/40\n",
      "175/175 [==============================] - 168s 958ms/step - loss: 0.1274 - tp: 310.0000 - fp: 191.0000 - tn: 754.0000 - fn: 145.0000 - accuracy: 0.7600 - precision: 0.6188 - recall: 0.6813 - auc: 0.7632 - binary_crossentropy: 1.8835 - val_loss: 0.1404 - val_tp: 93.0000 - val_fp: 46.0000 - val_tn: 178.0000 - val_fn: 27.0000 - val_accuracy: 0.7878 - val_precision: 0.6691 - val_recall: 0.7750 - val_auc: 0.8030 - val_binary_crossentropy: 1.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1272 - tp: 309.0000 - fp: 173.0000 - tn: 746.0000 - fn: 164.0000 - accuracy: 0.7579 - precision: 0.6411 - recall: 0.6533 - auc: 0.7751 - binary_crossentropy: 1.8143\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "175/175 [==============================] - 167s 956ms/step - loss: 0.1275 - tp: 309.0000 - fp: 176.0000 - tn: 751.0000 - fn: 164.0000 - accuracy: 0.7571 - precision: 0.6371 - recall: 0.6533 - auc: 0.7741 - binary_crossentropy: 1.8265 - val_loss: 0.1301 - val_tp: 98.0000 - val_fp: 54.0000 - val_tn: 172.0000 - val_fn: 20.0000 - val_accuracy: 0.7849 - val_precision: 0.6447 - val_recall: 0.8305 - val_auc: 0.8047 - val_binary_crossentropy: 2.1730\n",
      "Epoch 18/40\n",
      "175/175 [==============================] - 164s 940ms/step - loss: 0.1225 - tp: 320.0000 - fp: 179.0000 - tn: 758.0000 - fn: 143.0000 - accuracy: 0.7700 - precision: 0.6413 - recall: 0.6911 - auc: 0.7856 - binary_crossentropy: 1.7569 - val_loss: 0.2736 - val_tp: 107.0000 - val_fp: 181.0000 - val_tn: 47.0000 - val_fn: 9.0000 - val_accuracy: 0.4477 - val_precision: 0.3715 - val_recall: 0.9224 - val_auc: 0.8056 - val_binary_crossentropy: 3.3358\n",
      "Epoch 19/40\n",
      "175/175 [==============================] - 166s 947ms/step - loss: 0.1165 - tp: 307.0000 - fp: 168.0000 - tn: 780.0000 - fn: 145.0000 - accuracy: 0.7764 - precision: 0.6463 - recall: 0.6792 - auc: 0.7952 - binary_crossentropy: 1.7025 - val_loss: 0.1684 - val_tp: 110.0000 - val_fp: 66.0000 - val_tn: 146.0000 - val_fn: 22.0000 - val_accuracy: 0.7442 - val_precision: 0.6250 - val_recall: 0.8333 - val_auc: 0.7735 - val_binary_crossentropy: 2.4972\n",
      "Epoch 20/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1176 - tp: 320.0000 - fp: 179.0000 - tn: 756.0000 - fn: 137.0000 - accuracy: 0.7730 - precision: 0.6413 - recall: 0.7002 - auc: 0.7932 - binary_crossentropy: 1.5690\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "175/175 [==============================] - 164s 939ms/step - loss: 0.1175 - tp: 322.0000 - fp: 181.0000 - tn: 760.0000 - fn: 137.0000 - accuracy: 0.7729 - precision: 0.6402 - recall: 0.7015 - auc: 0.7937 - binary_crossentropy: 1.5666 - val_loss: 0.1345 - val_tp: 105.0000 - val_fp: 55.0000 - val_tn: 163.0000 - val_fn: 21.0000 - val_accuracy: 0.7791 - val_precision: 0.6562 - val_recall: 0.8333 - val_auc: 0.7783 - val_binary_crossentropy: 2.2278\n",
      "Epoch 21/40\n",
      "175/175 [==============================] - 164s 935ms/step - loss: 0.1202 - tp: 319.0000 - fp: 167.0000 - tn: 759.0000 - fn: 155.0000 - accuracy: 0.7700 - precision: 0.6564 - recall: 0.6730 - auc: 0.7904 - binary_crossentropy: 1.6878 - val_loss: 0.1273 - val_tp: 96.0000 - val_fp: 55.0000 - val_tn: 164.0000 - val_fn: 29.0000 - val_accuracy: 0.7558 - val_precision: 0.6358 - val_recall: 0.7680 - val_auc: 0.7721 - val_binary_crossentropy: 2.1044\n",
      "Epoch 22/40\n",
      "175/175 [==============================] - 165s 942ms/step - loss: 0.1234 - tp: 322.0000 - fp: 184.0000 - tn: 740.0000 - fn: 154.0000 - accuracy: 0.7586 - precision: 0.6364 - recall: 0.6765 - auc: 0.7872 - binary_crossentropy: 1.6513 - val_loss: 0.1245 - val_tp: 107.0000 - val_fp: 59.0000 - val_tn: 161.0000 - val_fn: 17.0000 - val_accuracy: 0.7791 - val_precision: 0.6446 - val_recall: 0.8629 - val_auc: 0.7872 - val_binary_crossentropy: 2.1429\n",
      "Epoch 23/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1197 - tp: 300.0000 - fp: 181.0000 - tn: 770.0000 - fn: 141.0000 - accuracy: 0.7687 - precision: 0.6237 - recall: 0.6803 - auc: 0.7883 - binary_crossentropy: 1.6277\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "175/175 [==============================] - 164s 936ms/step - loss: 0.1197 - tp: 303.0000 - fp: 182.0000 - tn: 773.0000 - fn: 142.0000 - accuracy: 0.7686 - precision: 0.6247 - recall: 0.6809 - auc: 0.7879 - binary_crossentropy: 1.6304 - val_loss: 0.1338 - val_tp: 93.0000 - val_fp: 58.0000 - val_tn: 168.0000 - val_fn: 25.0000 - val_accuracy: 0.7587 - val_precision: 0.6159 - val_recall: 0.7881 - val_auc: 0.7698 - val_binary_crossentropy: 2.1645\n",
      "Epoch 24/40\n",
      "175/175 [==============================] - 166s 948ms/step - loss: 0.1181 - tp: 311.0000 - fp: 178.0000 - tn: 774.0000 - fn: 137.0000 - accuracy: 0.7750 - precision: 0.6360 - recall: 0.6942 - auc: 0.7965 - binary_crossentropy: 1.6808 - val_loss: 0.1169 - val_tp: 91.0000 - val_fp: 56.0000 - val_tn: 174.0000 - val_fn: 23.0000 - val_accuracy: 0.7703 - val_precision: 0.6190 - val_recall: 0.7982 - val_auc: 0.8057 - val_binary_crossentropy: 2.0695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144548d1788>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05337323],\n",
       "       [0.00163467],\n",
       "       [0.00375983],\n",
       "       ...,\n",
       "       [0.9994019 ],\n",
       "       [0.00365946],\n",
       "       [0.69453037]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.053373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.088020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.999933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>0.999402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.003659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.694530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "0      ISIC_0052060  0.053373\n",
       "1      ISIC_0052349  0.001635\n",
       "2      ISIC_0058510  0.003760\n",
       "3      ISIC_0073313  0.003200\n",
       "4      ISIC_0073502  0.088020\n",
       "...             ...       ...\n",
       "10977  ISIC_9992485  0.001060\n",
       "10978  ISIC_9996992  0.999933\n",
       "10979  ISIC_9997917  0.999402\n",
       "10980  ISIC_9998234  0.003659\n",
       "10981  ISIC_9999302  0.694530\n",
       "\n",
       "[10982 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"dice_loss_unet_2d_images_hsv_augment_equal_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144548d1788>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_data': None,\n",
       " 'model': <tensorflow.python.keras.engine.training.Model at 0x14454688e48>,\n",
       " '_chief_worker_only': None,\n",
       " 'params': {'batch_size': None,\n",
       "  'epochs': 40,\n",
       "  'steps': 175,\n",
       "  'samples': 175,\n",
       "  'verbose': 0,\n",
       "  'do_validation': True,\n",
       "  'metrics': ['loss',\n",
       "   'tp',\n",
       "   'fp',\n",
       "   'tn',\n",
       "   'fn',\n",
       "   'accuracy',\n",
       "   'precision',\n",
       "   'recall',\n",
       "   'auc',\n",
       "   'binary_crossentropy',\n",
       "   'val_loss',\n",
       "   'val_tp',\n",
       "   'val_fp',\n",
       "   'val_tn',\n",
       "   'val_fn',\n",
       "   'val_accuracy',\n",
       "   'val_precision',\n",
       "   'val_recall',\n",
       "   'val_auc',\n",
       "   'val_binary_crossentropy']},\n",
       " 'epoch': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23],\n",
       " 'history': {'loss': [0.18326620702232632,\n",
       "   0.16054922363587787,\n",
       "   0.14894251244408743,\n",
       "   0.14946842734302793,\n",
       "   0.13945898784058436,\n",
       "   0.13888711188520703,\n",
       "   0.13552159300872257,\n",
       "   0.1338896206872804,\n",
       "   0.1356118094921112,\n",
       "   0.13198634011404856,\n",
       "   0.12996510241712841,\n",
       "   0.11923706242016384,\n",
       "   0.12382788922105517,\n",
       "   0.12516135671309062,\n",
       "   0.12451574870518275,\n",
       "   0.12741130526576724,\n",
       "   0.1275342927660261,\n",
       "   0.12248019954987935,\n",
       "   0.11650808802672795,\n",
       "   0.1175238995892661,\n",
       "   0.12023923997368131,\n",
       "   0.12339722224644252,\n",
       "   0.11970635226794651,\n",
       "   0.1181268259031432],\n",
       "  'tp': [323.0,\n",
       "   336.0,\n",
       "   341.0,\n",
       "   303.0,\n",
       "   314.0,\n",
       "   300.0,\n",
       "   301.0,\n",
       "   305.0,\n",
       "   302.0,\n",
       "   298.0,\n",
       "   322.0,\n",
       "   332.0,\n",
       "   315.0,\n",
       "   311.0,\n",
       "   317.0,\n",
       "   310.0,\n",
       "   309.0,\n",
       "   320.0,\n",
       "   307.0,\n",
       "   322.0,\n",
       "   319.0,\n",
       "   322.0,\n",
       "   303.0,\n",
       "   311.0],\n",
       "  'fp': [364.0,\n",
       "   298.0,\n",
       "   277.0,\n",
       "   242.0,\n",
       "   217.0,\n",
       "   217.0,\n",
       "   216.0,\n",
       "   204.0,\n",
       "   202.0,\n",
       "   189.0,\n",
       "   209.0,\n",
       "   189.0,\n",
       "   178.0,\n",
       "   206.0,\n",
       "   175.0,\n",
       "   191.0,\n",
       "   176.0,\n",
       "   179.0,\n",
       "   168.0,\n",
       "   181.0,\n",
       "   167.0,\n",
       "   184.0,\n",
       "   182.0,\n",
       "   178.0],\n",
       "  'tn': [579.0,\n",
       "   635.0,\n",
       "   662.0,\n",
       "   697.0,\n",
       "   713.0,\n",
       "   727.0,\n",
       "   737.0,\n",
       "   731.0,\n",
       "   728.0,\n",
       "   744.0,\n",
       "   730.0,\n",
       "   751.0,\n",
       "   755.0,\n",
       "   750.0,\n",
       "   753.0,\n",
       "   754.0,\n",
       "   751.0,\n",
       "   758.0,\n",
       "   780.0,\n",
       "   760.0,\n",
       "   759.0,\n",
       "   740.0,\n",
       "   773.0,\n",
       "   774.0],\n",
       "  'fn': [134.0,\n",
       "   131.0,\n",
       "   120.0,\n",
       "   158.0,\n",
       "   156.0,\n",
       "   156.0,\n",
       "   146.0,\n",
       "   160.0,\n",
       "   168.0,\n",
       "   169.0,\n",
       "   139.0,\n",
       "   128.0,\n",
       "   152.0,\n",
       "   133.0,\n",
       "   155.0,\n",
       "   145.0,\n",
       "   164.0,\n",
       "   143.0,\n",
       "   145.0,\n",
       "   137.0,\n",
       "   155.0,\n",
       "   154.0,\n",
       "   142.0,\n",
       "   137.0],\n",
       "  'accuracy': [0.64428574,\n",
       "   0.69357145,\n",
       "   0.7164286,\n",
       "   0.71428573,\n",
       "   0.7335714,\n",
       "   0.7335714,\n",
       "   0.74142855,\n",
       "   0.74,\n",
       "   0.73571426,\n",
       "   0.7442857,\n",
       "   0.75142854,\n",
       "   0.77357143,\n",
       "   0.76428574,\n",
       "   0.75785714,\n",
       "   0.76428574,\n",
       "   0.76,\n",
       "   0.75714284,\n",
       "   0.77,\n",
       "   0.7764286,\n",
       "   0.7728571,\n",
       "   0.77,\n",
       "   0.75857145,\n",
       "   0.76857144,\n",
       "   0.775],\n",
       "  'precision': [0.47016013,\n",
       "   0.52996844,\n",
       "   0.5517799,\n",
       "   0.5559633,\n",
       "   0.5913371,\n",
       "   0.58027077,\n",
       "   0.58220506,\n",
       "   0.59921414,\n",
       "   0.5992063,\n",
       "   0.6119096,\n",
       "   0.606403,\n",
       "   0.63723606,\n",
       "   0.6389452,\n",
       "   0.60154736,\n",
       "   0.6443089,\n",
       "   0.6187625,\n",
       "   0.6371134,\n",
       "   0.64128256,\n",
       "   0.6463158,\n",
       "   0.6401591,\n",
       "   0.6563786,\n",
       "   0.6363636,\n",
       "   0.62474227,\n",
       "   0.6359918],\n",
       "  'recall': [0.70678335,\n",
       "   0.71948606,\n",
       "   0.7396963,\n",
       "   0.6572668,\n",
       "   0.6680851,\n",
       "   0.65789473,\n",
       "   0.67337805,\n",
       "   0.65591395,\n",
       "   0.6425532,\n",
       "   0.63811564,\n",
       "   0.69848156,\n",
       "   0.7217391,\n",
       "   0.6745182,\n",
       "   0.7004505,\n",
       "   0.6716102,\n",
       "   0.6813187,\n",
       "   0.653277,\n",
       "   0.6911447,\n",
       "   0.6792035,\n",
       "   0.70152503,\n",
       "   0.6729958,\n",
       "   0.6764706,\n",
       "   0.6808989,\n",
       "   0.6941964],\n",
       "  'auc': [0.7171349,\n",
       "   0.73255205,\n",
       "   0.75258446,\n",
       "   0.7270877,\n",
       "   0.7405388,\n",
       "   0.7552629,\n",
       "   0.76417345,\n",
       "   0.75039846,\n",
       "   0.7635518,\n",
       "   0.77029026,\n",
       "   0.7782244,\n",
       "   0.8070421,\n",
       "   0.7824143,\n",
       "   0.7914522,\n",
       "   0.78891975,\n",
       "   0.76323277,\n",
       "   0.77412987,\n",
       "   0.78557664,\n",
       "   0.7952046,\n",
       "   0.7937322,\n",
       "   0.7903988,\n",
       "   0.78718764,\n",
       "   0.78789467,\n",
       "   0.7965256],\n",
       "  'binary_crossentropy': [1.6053251,\n",
       "   1.851725,\n",
       "   1.745591,\n",
       "   2.0277297,\n",
       "   1.969866,\n",
       "   1.8778754,\n",
       "   1.769862,\n",
       "   2.050556,\n",
       "   1.8669904,\n",
       "   1.8274548,\n",
       "   1.7792158,\n",
       "   1.6173954,\n",
       "   1.7174468,\n",
       "   1.6970396,\n",
       "   1.6898004,\n",
       "   1.8834949,\n",
       "   1.8265392,\n",
       "   1.7569396,\n",
       "   1.7025396,\n",
       "   1.5665518,\n",
       "   1.687757,\n",
       "   1.6513258,\n",
       "   1.6303855,\n",
       "   1.6807657],\n",
       "  'val_loss': [0.2420433108196702,\n",
       "   0.318312184062115,\n",
       "   0.3241279724725457,\n",
       "   0.3299397878175558,\n",
       "   0.32477434707242386,\n",
       "   0.25049076281314675,\n",
       "   0.32695281020430633,\n",
       "   0.3014580931427867,\n",
       "   0.12049077953710112,\n",
       "   0.3101921466200851,\n",
       "   0.1439873184575591,\n",
       "   0.28411822194276853,\n",
       "   0.22707895692004715,\n",
       "   0.11176044632529103,\n",
       "   0.2758182938708815,\n",
       "   0.1403967159432034,\n",
       "   0.13008142661216648,\n",
       "   0.27359372013530064,\n",
       "   0.16843867232633192,\n",
       "   0.13454034889853278,\n",
       "   0.1272621314192927,\n",
       "   0.12445189769184867,\n",
       "   0.1337673645033393,\n",
       "   0.11688811695852945],\n",
       "  'val_tp': [101.0,\n",
       "   125.0,\n",
       "   121.0,\n",
       "   117.0,\n",
       "   120.0,\n",
       "   122.0,\n",
       "   108.0,\n",
       "   114.0,\n",
       "   112.0,\n",
       "   123.0,\n",
       "   115.0,\n",
       "   125.0,\n",
       "   121.0,\n",
       "   90.0,\n",
       "   115.0,\n",
       "   93.0,\n",
       "   98.0,\n",
       "   107.0,\n",
       "   110.0,\n",
       "   105.0,\n",
       "   96.0,\n",
       "   107.0,\n",
       "   93.0,\n",
       "   91.0],\n",
       "  'val_fp': [85.0,\n",
       "   219.0,\n",
       "   223.0,\n",
       "   227.0,\n",
       "   224.0,\n",
       "   148.0,\n",
       "   229.0,\n",
       "   206.0,\n",
       "   58.0,\n",
       "   213.0,\n",
       "   59.0,\n",
       "   202.0,\n",
       "   123.0,\n",
       "   43.0,\n",
       "   178.0,\n",
       "   46.0,\n",
       "   54.0,\n",
       "   181.0,\n",
       "   66.0,\n",
       "   55.0,\n",
       "   55.0,\n",
       "   59.0,\n",
       "   58.0,\n",
       "   56.0],\n",
       "  'val_tn': [147.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   72.0,\n",
       "   4.0,\n",
       "   22.0,\n",
       "   156.0,\n",
       "   5.0,\n",
       "   155.0,\n",
       "   13.0,\n",
       "   95.0,\n",
       "   184.0,\n",
       "   42.0,\n",
       "   178.0,\n",
       "   172.0,\n",
       "   47.0,\n",
       "   146.0,\n",
       "   163.0,\n",
       "   164.0,\n",
       "   161.0,\n",
       "   168.0,\n",
       "   174.0],\n",
       "  'val_fn': [11.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   2.0,\n",
       "   3.0,\n",
       "   2.0,\n",
       "   18.0,\n",
       "   3.0,\n",
       "   15.0,\n",
       "   4.0,\n",
       "   5.0,\n",
       "   27.0,\n",
       "   9.0,\n",
       "   27.0,\n",
       "   20.0,\n",
       "   9.0,\n",
       "   22.0,\n",
       "   21.0,\n",
       "   29.0,\n",
       "   17.0,\n",
       "   25.0,\n",
       "   23.0],\n",
       "  'val_accuracy': [0.7209302,\n",
       "   0.3633721,\n",
       "   0.35174417,\n",
       "   0.3401163,\n",
       "   0.3488372,\n",
       "   0.56395346,\n",
       "   0.3255814,\n",
       "   0.39534885,\n",
       "   0.7790698,\n",
       "   0.37209302,\n",
       "   0.78488374,\n",
       "   0.4011628,\n",
       "   0.627907,\n",
       "   0.79651165,\n",
       "   0.45639536,\n",
       "   0.7877907,\n",
       "   0.78488374,\n",
       "   0.44767442,\n",
       "   0.74418604,\n",
       "   0.7790698,\n",
       "   0.75581396,\n",
       "   0.7790698,\n",
       "   0.75872093,\n",
       "   0.77034885],\n",
       "  'val_precision': [0.5430108,\n",
       "   0.3633721,\n",
       "   0.35174417,\n",
       "   0.3401163,\n",
       "   0.3488372,\n",
       "   0.45185184,\n",
       "   0.32047477,\n",
       "   0.35625,\n",
       "   0.65882355,\n",
       "   0.36607143,\n",
       "   0.66091955,\n",
       "   0.382263,\n",
       "   0.49590164,\n",
       "   0.6766917,\n",
       "   0.39249146,\n",
       "   0.66906476,\n",
       "   0.6447368,\n",
       "   0.3715278,\n",
       "   0.625,\n",
       "   0.65625,\n",
       "   0.6357616,\n",
       "   0.64457834,\n",
       "   0.615894,\n",
       "   0.61904764],\n",
       "  'val_recall': [0.90178573,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.983871,\n",
       "   0.972973,\n",
       "   0.98275864,\n",
       "   0.86153847,\n",
       "   0.97619045,\n",
       "   0.88461536,\n",
       "   0.96899223,\n",
       "   0.96031743,\n",
       "   0.7692308,\n",
       "   0.92741936,\n",
       "   0.775,\n",
       "   0.8305085,\n",
       "   0.92241377,\n",
       "   0.8333333,\n",
       "   0.8333333,\n",
       "   0.768,\n",
       "   0.86290324,\n",
       "   0.7881356,\n",
       "   0.7982456],\n",
       "  'val_auc': [0.7724369,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.6853609,\n",
       "   0.7892595,\n",
       "   0.7388741,\n",
       "   0.7540835,\n",
       "   0.83366287,\n",
       "   0.7026722,\n",
       "   0.8357656,\n",
       "   0.76789254,\n",
       "   0.8011141,\n",
       "   0.8188374,\n",
       "   0.7699047,\n",
       "   0.80299467,\n",
       "   0.80465347,\n",
       "   0.8056375,\n",
       "   0.77349555,\n",
       "   0.7783238,\n",
       "   0.77212787,\n",
       "   0.78724337,\n",
       "   0.76983654,\n",
       "   0.8057399],\n",
       "  'val_binary_crossentropy': [0.7445,\n",
       "   8.096296,\n",
       "   10.595917,\n",
       "   12.713927,\n",
       "   5.959749,\n",
       "   3.4185698,\n",
       "   5.938268,\n",
       "   6.046669,\n",
       "   2.0323474,\n",
       "   5.3668346,\n",
       "   1.609214,\n",
       "   3.8484182,\n",
       "   3.2987251,\n",
       "   1.6584026,\n",
       "   3.2732115,\n",
       "   1.3946079,\n",
       "   2.1730301,\n",
       "   3.3358033,\n",
       "   2.497216,\n",
       "   2.227783,\n",
       "   2.1044412,\n",
       "   2.1429253,\n",
       "   2.164461,\n",
       "   2.0694838],\n",
       "  'lr': [1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   1e-04,\n",
       "   5e-05,\n",
       "   5e-05,\n",
       "   5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   2.5e-05,\n",
       "   1.25e-05,\n",
       "   1.25e-05,\n",
       "   1.25e-05,\n",
       "   1.25e-05,\n",
       "   1.25e-05,\n",
       "   6.25e-06,\n",
       "   6.25e-06,\n",
       "   6.25e-06,\n",
       "   3.125e-06,\n",
       "   3.125e-06,\n",
       "   3.125e-06,\n",
       "   1.5625e-06]}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = history.history[\"loss\"]\n",
    "val_loss_ = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (11,) and (24,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-1b4b1d511041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2761\u001b[0m     return gca().plot(\n\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2763\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \"\"\"\n\u001b[0;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (11,) and (24,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss_, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_, 'b', label=\"validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
