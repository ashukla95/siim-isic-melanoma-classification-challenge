{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Conv2D, UpSampling2D, Conv2DTranspose, concatenate, MaxPooling2D, \n",
    "                                     Activation, Dropout, Cropping2D, Flatten, Dense, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 300\n",
    "IMG_WIDTH = 300\n",
    "TRAIN_IMAGE_PATH = \"jpeg/train/\"\n",
    "TEST_IMAGE_PATH = \"jpeg/test/\"\n",
    "BATCH_SIZE = 8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REG = 0.0005\n",
    "EPOCHS=40\n",
    "METRICS = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.binary_crossentropy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_name\"] = train_df[\"image_name\"].apply(lambda x: TRAIN_IMAGE_PATH + x + \".jpg\")\n",
    "test_df[\"image_name\"] = test_df[\"image_name\"].apply(lambda x: TEST_IMAGE_PATH + x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target_1 = train_df[train_df[\"target\"] == 1]\n",
    "train_df_target_0 = train_df[train_df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_target_0 = np.random.randint(low=1, high=train_df_target_0.shape[0], \n",
    "                                    size=2 * train_df_target_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_d = pd.concat([train_df_target_0.iloc[random_target_0], train_df_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "#image = tf.cast(image, tf.float32)/255.0\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    r_crop = np.random.uniform(low = 0.4, high = 1.0)\n",
    "    r_rsize = np.random.uniform(low = 0.8, high = 1.2)\n",
    "    image = tf.image.random_crop(image, (int(r_crop*IMG_HEIGHT), int(r_crop*IMG_WIDTH), 3))\n",
    "    image = tf.image.rot90(image)\n",
    "    image = tf.keras.preprocessing.image.random_shear(image, 20)\n",
    "    image = tf.image.resize(image, (int(r_rsize*IMG_HEIGHT), int(r_rsize*IMG_WIDTH), 3), preserve_aspect_ratio=True)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.random_brightness(image, lower=0.7, upper=1.3)\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "#     image = tf.image.rgb_to_hsv(image)\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.adjust_brightness(image, 0.2)\n",
    "#     image = tf.image.rot90(image)\n",
    "#     image = tf.image.central_crop(image, central_fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df_d[[\"image_name\"]]\n",
    "y_train = train_df_d[\"target\"].astype(np.float32).values\n",
    "x_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1401, 1), (351, 1), (1401,), (351,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74600639, 1.51623377])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset\n",
    "                 .from_tensor_slices((x_train[\"image_name\"].values, y_train))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .repeat()\n",
    "                 .shuffle(512)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = (tf.data.Dataset\n",
    "               .from_tensor_slices((x_val[\"image_name\"].values, y_val))\n",
    "               .map(decode_image, num_parallel_calls=AUTO)\n",
    "               .repeat()\n",
    "               .shuffle(512)\n",
    "               .batch(BATCH_SIZE)\n",
    "               .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.image_name))\n",
    "                .map(decode_image, num_parallel_calls=AUTO)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",\n",
    "    patience=3,\n",
    "    min_lr=0.000001,\n",
    "    factor=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkpt = ModelCheckpoint(filepath=\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        print(\"target: {} {}, refer: {} {}\".format(target, target.get_shape(), refer, refer.get_shape()))\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "    return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: Tensor(\"conv2d_7/Identity:0\", shape=(None, 37, 37, 96), dtype=float32) (None, 37, 37, 96), refer: Tensor(\"up_sampling2d/Identity:0\", shape=(None, 36, 36, 120), dtype=float32) (None, 36, 36, 120)\n",
      "target: Tensor(\"conv2d_5/Identity:0\", shape=(None, 75, 75, 72), dtype=float32) (None, 75, 75, 72), refer: Tensor(\"up_sampling2d_1/Identity:0\", shape=(None, 72, 72, 256), dtype=float32) (None, 72, 72, 256)\n",
      "target: Tensor(\"conv2d_3/Identity:0\", shape=(None, 150, 150, 48), dtype=float32) (None, 150, 150, 48), refer: Tensor(\"up_sampling2d_2/Identity:0\", shape=(None, 144, 144, 192), dtype=float32) (None, 144, 144, 192)\n",
      "target: Tensor(\"conv2d_1/Identity:0\", shape=(None, 300, 300, 24), dtype=float32) (None, 300, 300, 24), refer: Tensor(\"up_sampling2d_3/Identity:0\", shape=(None, 288, 288, 192), dtype=float32) (None, 288, 288, 192)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 300, 300, 24) 672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 300, 300, 24) 5208        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 150, 150, 24) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150, 150, 24) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 48) 10416       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 48) 20784       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 48)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 75, 75, 48)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 72)   31176       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 72)   46728       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 72)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 37, 37, 72)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 37, 37, 96)   62304       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 37, 37, 96)   83040       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 18, 18, 96)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 18, 18, 96)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 18, 18, 120)  103800      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 18, 18, 120)  129720      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 36, 36, 120)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 36, 36, 96)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 36, 36, 216)  0           up_sampling2d[0][0]              \n",
      "                                                                 cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 36, 36, 216)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 36, 36, 256)  497920      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 36, 36, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 72, 72, 256)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 72, 72, 72)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 328)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 72, 72, 328)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 192)  566976      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 192)  331968      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 144, 144, 192 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 144, 144, 48) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144, 144, 240 0           up_sampling2d_2[0][0]            \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 144, 144, 240 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 144, 144, 192 414912      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 144, 144, 192 331968      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 288, 288, 192 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 288, 288, 24) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 288, 288, 216 0           up_sampling2d_3[0][0]            \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 288, 288, 216 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 288, 288, 64) 124480      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 288, 288, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 288, 288, 1)  65          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 82944)        0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          42467840    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 46,024,922\n",
      "Trainable params: 46,023,130\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_unet(input_layer, expansion_filters=64, expansion_kernel=(3,3), expansion_pool_size=(2,2),\n",
    "          contract_filters=64, contract_kernel=(3,3), contract_pool_size=(2,2)):\n",
    "    \n",
    "    #64\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    lvl_1 = Conv2D(filters=expansion_filters, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_1)\n",
    "    mp_lvl_1 = MaxPooling2D(expansion_pool_size)(lvl_1)\n",
    "    mp_lvl_1 = Dropout(0.25)(mp_lvl_1)\n",
    "    \n",
    "    #128\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_1)\n",
    "    lvl_2 = Conv2D(filters=expansion_filters*2, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_2)\n",
    "    mp_lvl_2 = MaxPooling2D(expansion_pool_size)(lvl_2)\n",
    "    mp_lvl_2 = Dropout(0.25)(mp_lvl_2)\n",
    "    \n",
    "    #256\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_2)\n",
    "    lvl_3 = Conv2D(filters=expansion_filters*3, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_3)\n",
    "    mp_lvl_3 = MaxPooling2D(expansion_pool_size)(lvl_3)\n",
    "    mp_lvl_3 = Dropout(0.25)(mp_lvl_3)\n",
    "    \n",
    "    #512\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_3)\n",
    "    lvl_4 = Conv2D(filters=expansion_filters*4, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_4)\n",
    "    mp_lvl_4 = MaxPooling2D(expansion_pool_size)(lvl_4)\n",
    "    mp_lvl_4 = Dropout(0.25)(mp_lvl_4)\n",
    "    \n",
    "    #1024\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(mp_lvl_4)\n",
    "    lvl_5 = Conv2D(filters=expansion_filters*5, kernel_size=expansion_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    \n",
    "    #d_lvl_4 = Conv2DTranspose(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(lvl_5)\n",
    "    d_lvl_4 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(lvl_5)\n",
    "    ch, cw = get_crop_shape(lvl_4, d_lvl_4)\n",
    "    ccon_4 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_4)\n",
    "    ucon_4 = concatenate([d_lvl_4, ccon_4])\n",
    "    ucon_4 = Dropout(0.25)(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    ucon_4 = Conv2D(filters=contract_filters*4, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    \n",
    "    #d_lvl_3 = Conv2DTranspose(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_4)\n",
    "    d_lvl_3 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_4)\n",
    "    ch, cw = get_crop_shape(lvl_3, d_lvl_3)\n",
    "    ccon_3 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_3)\n",
    "    ucon_3 = concatenate([d_lvl_3, ccon_3])\n",
    "    ucon_3 = Dropout(0.25)(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    ucon_3 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    \n",
    "    #d_lvl_2 = Conv2DTranspose(filters=contract_filters*2, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_3)\n",
    "    d_lvl_2 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_3)\n",
    "    ch, cw = get_crop_shape(lvl_2, d_lvl_2)\n",
    "    ccon_2 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_2)\n",
    "    ucon_2 = concatenate([d_lvl_2, ccon_2])\n",
    "    ucon_2 = Dropout(0.25)(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    ucon_2 = Conv2D(filters=contract_filters*3, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    \n",
    "    #d_lvl_1 = Conv2DTranspose(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_2)\n",
    "    d_lvl_1 = UpSampling2D(size=contract_pool_size, data_format=\"channels_last\")(ucon_2)\n",
    "    ch, cw = get_crop_shape(lvl_1, d_lvl_1)\n",
    "    ccon_1 = Cropping2D(cropping=(ch, cw), data_format=\"channels_last\")(lvl_1)\n",
    "    ucon_1 = concatenate([d_lvl_1, ccon_1])\n",
    "    ucon_1 = Dropout(0.25)(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    ucon_1 = Conv2D(filters=contract_filters*1, kernel_size=contract_kernel, activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    output = Conv2D(filters=1, kernel_size=(1,1), activation=\"relu\", padding=\"same\")(ucon_1)\n",
    "    \n",
    "    flatten = Flatten()(output)\n",
    "    dense4 = Dense(512, activation='relu')(flatten)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    dense3 = Dense(256, activation='relu')(bn4)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    dense2 = Dense(128, activation='relu')(bn3)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    dense1 = Dense(1, activation=\"sigmoid\")(bn2)\n",
    "    model = Model(inputs=input_layer, outputs=dense1)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "input_layer = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model = model_unet(input_layer, expansion_filters=24)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x1fdfa4e9048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=dice_loss, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 175 steps, validate for 43 steps\n",
      "Epoch 1/40\n",
      "175/175 [==============================] - 255s 1s/step - loss: 0.1850 - tp: 288.0000 - fp: 315.0000 - tn: 627.0000 - fn: 170.0000 - accuracy: 0.6536 - precision: 0.4776 - recall: 0.6288 - auc: 0.6994 - binary_crossentropy: 1.5910 - val_loss: 0.2240 - val_tp: 111.0000 - val_fp: 125.0000 - val_tn: 91.0000 - val_fn: 17.0000 - val_accuracy: 0.5872 - val_precision: 0.4703 - val_recall: 0.8672 - val_auc: 0.7180 - val_binary_crossentropy: 1.4952\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 210s 1s/step - loss: 0.1577 - tp: 309.0000 - fp: 265.0000 - tn: 671.0000 - fn: 155.0000 - accuracy: 0.7000 - precision: 0.5383 - recall: 0.6659 - auc: 0.7322 - binary_crossentropy: 1.7625 - val_loss: 0.2218 - val_tp: 116.0000 - val_fp: 118.0000 - val_tn: 109.0000 - val_fn: 1.0000 - val_accuracy: 0.6541 - val_precision: 0.4957 - val_recall: 0.9915 - val_auc: 0.8337 - val_binary_crossentropy: 1.8068\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 218s 1s/step - loss: 0.1480 - tp: 295.0000 - fp: 229.0000 - tn: 709.0000 - fn: 167.0000 - accuracy: 0.7171 - precision: 0.5630 - recall: 0.6385 - auc: 0.7542 - binary_crossentropy: 1.6198 - val_loss: 0.3212 - val_tp: 123.0000 - val_fp: 221.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3576 - val_precision: 0.3576 - val_recall: 1.0000 - val_auc: 0.5004 - val_binary_crossentropy: 8.1432\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 212s 1s/step - loss: 0.1505 - tp: 298.0000 - fp: 240.0000 - tn: 696.0000 - fn: 166.0000 - accuracy: 0.7100 - precision: 0.5539 - recall: 0.6422 - auc: 0.7529 - binary_crossentropy: 1.6500 - val_loss: 0.1405 - val_tp: 51.0000 - val_fp: 29.0000 - val_tn: 196.0000 - val_fn: 68.0000 - val_accuracy: 0.7180 - val_precision: 0.6375 - val_recall: 0.4286 - val_auc: 0.7954 - val_binary_crossentropy: 0.8589\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 209s 1s/step - loss: 0.1463 - tp: 301.0000 - fp: 234.0000 - tn: 704.0000 - fn: 161.0000 - accuracy: 0.7179 - precision: 0.5626 - recall: 0.6515 - auc: 0.7468 - binary_crossentropy: 1.8058 - val_loss: 0.3270 - val_tp: 119.0000 - val_fp: 225.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3459 - val_precision: 0.3459 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 12.1521\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 211s 1s/step - loss: 0.1477 - tp: 307.0000 - fp: 256.0000 - tn: 691.0000 - fn: 146.0000 - accuracy: 0.7129 - precision: 0.5453 - recall: 0.6777 - auc: 0.7503 - binary_crossentropy: 1.8879 - val_loss: 0.3270 - val_tp: 119.0000 - val_fp: 225.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3459 - val_precision: 0.3459 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 10.1239\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 213s 1s/step - loss: 0.1397 - tp: 314.0000 - fp: 218.0000 - tn: 712.0000 - fn: 156.0000 - accuracy: 0.7329 - precision: 0.5902 - recall: 0.6681 - auc: 0.7682 - binary_crossentropy: 1.5633 - val_loss: 0.3198 - val_tp: 124.0000 - val_fp: 220.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3605 - val_precision: 0.3605 - val_recall: 1.0000 - val_auc: 0.5000 - val_binary_crossentropy: 13.1919\n",
      "Epoch 8/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1415 - tp: 300.0000 - fp: 211.0000 - tn: 716.0000 - fn: 165.0000 - accuracy: 0.7299 - precision: 0.5871 - recall: 0.6452 - auc: 0.7507 - binary_crossentropy: 1.7701\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "175/175 [==============================] - 211s 1s/step - loss: 0.1412 - tp: 301.0000 - fp: 212.0000 - tn: 722.0000 - fn: 165.0000 - accuracy: 0.7307 - precision: 0.5867 - recall: 0.6459 - auc: 0.7514 - binary_crossentropy: 1.7622 - val_loss: 0.3122 - val_tp: 129.0000 - val_fp: 215.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5093 - val_binary_crossentropy: 6.8681\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 216s 1s/step - loss: 0.1333 - tp: 291.0000 - fp: 194.0000 - tn: 750.0000 - fn: 165.0000 - accuracy: 0.7436 - precision: 0.6000 - recall: 0.6382 - auc: 0.7678 - binary_crossentropy: 1.7056 - val_loss: 0.3061 - val_tp: 129.0000 - val_fp: 213.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3808 - val_precision: 0.3772 - val_recall: 1.0000 - val_auc: 0.6978 - val_binary_crossentropy: 4.4653\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 204s 1s/step - loss: 0.1402 - tp: 295.0000 - fp: 216.0000 - tn: 721.0000 - fn: 168.0000 - accuracy: 0.7257 - precision: 0.5773 - recall: 0.6371 - auc: 0.7631 - binary_crossentropy: 1.8525 - val_loss: 0.1330 - val_tp: 116.0000 - val_fp: 62.0000 - val_tn: 147.0000 - val_fn: 19.0000 - val_accuracy: 0.7645 - val_precision: 0.6517 - val_recall: 0.8593 - val_auc: 0.8573 - val_binary_crossentropy: 0.8298\n",
      "Epoch 11/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1411 - tp: 280.0000 - fp: 209.0000 - tn: 727.0000 - fn: 176.0000 - accuracy: 0.7234 - precision: 0.5726 - recall: 0.6140 - auc: 0.7560 - binary_crossentropy: 1.8062\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "175/175 [==============================] - 209s 1s/step - loss: 0.1411 - tp: 280.0000 - fp: 211.0000 - tn: 733.0000 - fn: 176.0000 - accuracy: 0.7236 - precision: 0.5703 - recall: 0.6140 - auc: 0.7555 - binary_crossentropy: 1.8148 - val_loss: 0.3160 - val_tp: 118.0000 - val_fp: 217.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3692 - val_precision: 0.3522 - val_recall: 1.0000 - val_auc: 0.6832 - val_binary_crossentropy: 5.2013\n",
      "Epoch 12/40\n",
      "175/175 [==============================] - 194s 1s/step - loss: 0.1265 - tp: 319.0000 - fp: 188.0000 - tn: 737.0000 - fn: 156.0000 - accuracy: 0.7543 - precision: 0.6292 - recall: 0.6716 - auc: 0.7786 - binary_crossentropy: 1.7000 - val_loss: 0.2942 - val_tp: 118.0000 - val_fp: 206.0000 - val_tn: 17.0000 - val_fn: 3.0000 - val_accuracy: 0.3924 - val_precision: 0.3642 - val_recall: 0.9752 - val_auc: 0.7850 - val_binary_crossentropy: 3.7204\n",
      "Epoch 13/40\n",
      "175/175 [==============================] - 194s 1s/step - loss: 0.1390 - tp: 294.0000 - fp: 211.0000 - tn: 732.0000 - fn: 163.0000 - accuracy: 0.7329 - precision: 0.5822 - recall: 0.6433 - auc: 0.7490 - binary_crossentropy: 1.9539 - val_loss: 0.2295 - val_tp: 121.0000 - val_fp: 123.0000 - val_tn: 91.0000 - val_fn: 9.0000 - val_accuracy: 0.6163 - val_precision: 0.4959 - val_recall: 0.9308 - val_auc: 0.7951 - val_binary_crossentropy: 2.3367\n",
      "Epoch 14/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1229 - tp: 299.0000 - fp: 184.0000 - tn: 765.0000 - fn: 144.0000 - accuracy: 0.7644 - precision: 0.6190 - recall: 0.6749 - auc: 0.7906 - binary_crossentropy: 1.6206\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "175/175 [==============================] - 195s 1s/step - loss: 0.1232 - tp: 301.0000 - fp: 184.0000 - tn: 768.0000 - fn: 147.0000 - accuracy: 0.7636 - precision: 0.6206 - recall: 0.6719 - auc: 0.7893 - binary_crossentropy: 1.6223 - val_loss: 0.2357 - val_tp: 103.0000 - val_fp: 128.0000 - val_tn: 98.0000 - val_fn: 15.0000 - val_accuracy: 0.5843 - val_precision: 0.4459 - val_recall: 0.8729 - val_auc: 0.7933 - val_binary_crossentropy: 1.2925\n",
      "Epoch 15/40\n",
      "175/175 [==============================] - 195s 1s/step - loss: 0.1176 - tp: 318.0000 - fp: 155.0000 - tn: 777.0000 - fn: 150.0000 - accuracy: 0.7821 - precision: 0.6723 - recall: 0.6795 - auc: 0.7964 - binary_crossentropy: 1.4787 - val_loss: 0.1437 - val_tp: 100.0000 - val_fp: 54.0000 - val_tn: 167.0000 - val_fn: 23.0000 - val_accuracy: 0.7762 - val_precision: 0.6494 - val_recall: 0.8130 - val_auc: 0.8169 - val_binary_crossentropy: 1.4817\n",
      "Epoch 16/40\n",
      "175/175 [==============================] - 193s 1s/step - loss: 0.1256 - tp: 311.0000 - fp: 171.0000 - tn: 755.0000 - fn: 163.0000 - accuracy: 0.7614 - precision: 0.6452 - recall: 0.6561 - auc: 0.7792 - binary_crossentropy: 1.6133 - val_loss: 0.1507 - val_tp: 80.0000 - val_fp: 55.0000 - val_tn: 180.0000 - val_fn: 29.0000 - val_accuracy: 0.7558 - val_precision: 0.5926 - val_recall: 0.7339 - val_auc: 0.7633 - val_binary_crossentropy: 1.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1275 - tp: 292.0000 - fp: 171.0000 - tn: 757.0000 - fn: 172.0000 - accuracy: 0.7536 - precision: 0.6307 - recall: 0.6293 - auc: 0.7670 - binary_crossentropy: 1.7680\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "175/175 [==============================] - 193s 1s/step - loss: 0.1269 - tp: 293.0000 - fp: 171.0000 - tn: 764.0000 - fn: 172.0000 - accuracy: 0.7550 - precision: 0.6315 - recall: 0.6301 - auc: 0.7676 - binary_crossentropy: 1.7580 - val_loss: 0.1088 - val_tp: 83.0000 - val_fp: 37.0000 - val_tn: 184.0000 - val_fn: 40.0000 - val_accuracy: 0.7762 - val_precision: 0.6917 - val_recall: 0.6748 - val_auc: 0.8369 - val_binary_crossentropy: 1.1323\n",
      "Epoch 18/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1248 - tp: 287.0000 - fp: 181.0000 - tn: 769.0000 - fn: 163.0000 - accuracy: 0.7543 - precision: 0.6132 - recall: 0.6378 - auc: 0.7859 - binary_crossentropy: 1.7667 - val_loss: 0.1163 - val_tp: 104.0000 - val_fp: 51.0000 - val_tn: 163.0000 - val_fn: 26.0000 - val_accuracy: 0.7762 - val_precision: 0.6710 - val_recall: 0.8000 - val_auc: 0.8286 - val_binary_crossentropy: 1.5749\n",
      "Epoch 19/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1219 - tp: 304.0000 - fp: 179.0000 - tn: 755.0000 - fn: 162.0000 - accuracy: 0.7564 - precision: 0.6294 - recall: 0.6524 - auc: 0.7999 - binary_crossentropy: 1.5898 - val_loss: 0.0955 - val_tp: 66.0000 - val_fp: 24.0000 - val_tn: 213.0000 - val_fn: 41.0000 - val_accuracy: 0.8110 - val_precision: 0.7333 - val_recall: 0.6168 - val_auc: 0.8657 - val_binary_crossentropy: 0.8662\n",
      "Epoch 20/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1229 - tp: 290.0000 - fp: 185.0000 - tn: 771.0000 - fn: 146.0000 - accuracy: 0.7622 - precision: 0.6105 - recall: 0.6651 - auc: 0.7780 - binary_crossentropy: 1.7632\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1230 - tp: 292.0000 - fp: 187.0000 - tn: 774.0000 - fn: 147.0000 - accuracy: 0.7614 - precision: 0.6096 - recall: 0.6651 - auc: 0.7782 - binary_crossentropy: 1.7614 - val_loss: 0.1014 - val_tp: 103.0000 - val_fp: 34.0000 - val_tn: 173.0000 - val_fn: 34.0000 - val_accuracy: 0.8023 - val_precision: 0.7518 - val_recall: 0.7518 - val_auc: 0.8513 - val_binary_crossentropy: 1.2573\n",
      "Epoch 21/40\n",
      "175/175 [==============================] - 193s 1s/step - loss: 0.1287 - tp: 309.0000 - fp: 182.0000 - tn: 748.0000 - fn: 161.0000 - accuracy: 0.7550 - precision: 0.6293 - recall: 0.6574 - auc: 0.7697 - binary_crossentropy: 1.7399 - val_loss: 0.0969 - val_tp: 99.0000 - val_fp: 39.0000 - val_tn: 184.0000 - val_fn: 22.0000 - val_accuracy: 0.8227 - val_precision: 0.7174 - val_recall: 0.8182 - val_auc: 0.8405 - val_binary_crossentropy: 1.3778\n",
      "Epoch 22/40\n",
      "175/175 [==============================] - 193s 1s/step - loss: 0.1265 - tp: 308.0000 - fp: 183.0000 - tn: 754.0000 - fn: 155.0000 - accuracy: 0.7586 - precision: 0.6273 - recall: 0.6652 - auc: 0.7841 - binary_crossentropy: 1.7552 - val_loss: 0.1125 - val_tp: 92.0000 - val_fp: 52.0000 - val_tn: 176.0000 - val_fn: 24.0000 - val_accuracy: 0.7791 - val_precision: 0.6389 - val_recall: 0.7931 - val_auc: 0.8250 - val_binary_crossentropy: 1.7563\n",
      "Epoch 23/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1314 - tp: 289.0000 - fp: 176.0000 - tn: 748.0000 - fn: 179.0000 - accuracy: 0.7450 - precision: 0.6215 - recall: 0.6175 - auc: 0.7661 - binary_crossentropy: 1.8174\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1313 - tp: 290.0000 - fp: 177.0000 - tn: 753.0000 - fn: 180.0000 - accuracy: 0.7450 - precision: 0.6210 - recall: 0.6170 - auc: 0.7665 - binary_crossentropy: 1.8110 - val_loss: 0.1111 - val_tp: 70.0000 - val_fp: 33.0000 - val_tn: 196.0000 - val_fn: 45.0000 - val_accuracy: 0.7733 - val_precision: 0.6796 - val_recall: 0.6087 - val_auc: 0.8203 - val_binary_crossentropy: 1.2052\n",
      "Epoch 24/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1256 - tp: 290.0000 - fp: 186.0000 - tn: 767.0000 - fn: 157.0000 - accuracy: 0.7550 - precision: 0.6092 - recall: 0.6488 - auc: 0.7835 - binary_crossentropy: 1.6920 - val_loss: 0.1076 - val_tp: 96.0000 - val_fp: 38.0000 - val_tn: 172.0000 - val_fn: 38.0000 - val_accuracy: 0.7791 - val_precision: 0.7164 - val_recall: 0.7164 - val_auc: 0.8434 - val_binary_crossentropy: 1.5032\n",
      "Epoch 25/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1185 - tp: 317.0000 - fp: 156.0000 - tn: 766.0000 - fn: 161.0000 - accuracy: 0.7736 - precision: 0.6702 - recall: 0.6632 - auc: 0.7875 - binary_crossentropy: 1.6517 - val_loss: 0.1127 - val_tp: 84.0000 - val_fp: 44.0000 - val_tn: 187.0000 - val_fn: 29.0000 - val_accuracy: 0.7878 - val_precision: 0.6562 - val_recall: 0.7434 - val_auc: 0.8226 - val_binary_crossentropy: 1.4839\n",
      "Epoch 26/40\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.1157 - tp: 314.0000 - fp: 164.0000 - tn: 770.0000 - fn: 144.0000 - accuracy: 0.7787 - precision: 0.6569 - recall: 0.6856 - auc: 0.7862 - binary_crossentropy: 1.6772\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1156 - tp: 316.0000 - fp: 165.0000 - tn: 774.0000 - fn: 145.0000 - accuracy: 0.7786 - precision: 0.6570 - recall: 0.6855 - auc: 0.7873 - binary_crossentropy: 1.6693 - val_loss: 0.1032 - val_tp: 93.0000 - val_fp: 38.0000 - val_tn: 183.0000 - val_fn: 30.0000 - val_accuracy: 0.8023 - val_precision: 0.7099 - val_recall: 0.7561 - val_auc: 0.8442 - val_binary_crossentropy: 1.4013\n",
      "Epoch 27/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1168 - tp: 302.0000 - fp: 161.0000 - tn: 783.0000 - fn: 154.0000 - accuracy: 0.7750 - precision: 0.6523 - recall: 0.6623 - auc: 0.8008 - binary_crossentropy: 1.5753 - val_loss: 0.1082 - val_tp: 95.0000 - val_fp: 33.0000 - val_tn: 175.0000 - val_fn: 41.0000 - val_accuracy: 0.7849 - val_precision: 0.7422 - val_recall: 0.6985 - val_auc: 0.8547 - val_binary_crossentropy: 1.2183\n",
      "Epoch 28/40\n",
      "175/175 [==============================] - 192s 1s/step - loss: 0.1208 - tp: 303.0000 - fp: 171.0000 - tn: 769.0000 - fn: 157.0000 - accuracy: 0.7657 - precision: 0.6392 - recall: 0.6587 - auc: 0.7800 - binary_crossentropy: 1.7153 - val_loss: 0.1104 - val_tp: 67.0000 - val_fp: 31.0000 - val_tn: 203.0000 - val_fn: 43.0000 - val_accuracy: 0.7849 - val_precision: 0.6837 - val_recall: 0.6091 - val_auc: 0.8445 - val_binary_crossentropy: 1.2255\n",
      "Epoch 29/40\n",
      "175/175 [==============================] - 193s 1s/step - loss: 0.1195 - tp: 307.0000 - fp: 169.0000 - tn: 774.0000 - fn: 150.0000 - accuracy: 0.7721 - precision: 0.6450 - recall: 0.6718 - auc: 0.7890 - binary_crossentropy: 1.6783 - val_loss: 0.1174 - val_tp: 73.0000 - val_fp: 32.0000 - val_tn: 192.0000 - val_fn: 47.0000 - val_accuracy: 0.7703 - val_precision: 0.6952 - val_recall: 0.6083 - val_auc: 0.8368 - val_binary_crossentropy: 1.4563\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, es, model_chkpt],\n",
    "                        steps_per_epoch=x_train.shape[0]//BATCH_SIZE, validation_data=val_dataset,\n",
    "                        validation_steps=x_val.shape[0]//BATCH_SIZE,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fdfa72ea48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00797546],\n",
       "       [0.00262979],\n",
       "       [0.00218161],\n",
       "       ...,\n",
       "       [0.9999999 ],\n",
       "       [0.00299781],\n",
       "       [0.17615633]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[\"target\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.007975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.002630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.058733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>ISIC_9992485</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>ISIC_9996992</td>\n",
       "      <td>0.866623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>ISIC_9997917</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ISIC_9998234</td>\n",
       "      <td>0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>ISIC_9999302</td>\n",
       "      <td>0.176156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target\n",
       "0      ISIC_0052060  0.007975\n",
       "1      ISIC_0052349  0.002630\n",
       "2      ISIC_0058510  0.002182\n",
       "3      ISIC_0073313  0.001730\n",
       "4      ISIC_0073502  0.058733\n",
       "...             ...       ...\n",
       "10977  ISIC_9992485  0.001006\n",
       "10978  ISIC_9996992  0.866623\n",
       "10979  ISIC_9997917  1.000000\n",
       "10980  ISIC_9998234  0.002998\n",
       "10981  ISIC_9999302  0.176156\n",
       "\n",
       "[10982 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.to_csv(\"dice_loss_unet_2d_barzil_researcher_image_augmentation_exp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = history.history[\"loss\"]\n",
    "val_loss_ = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
